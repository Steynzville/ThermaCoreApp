======================================================================================
THERMACOREAPP WORKFLOW EXECUTION REPORT
======================================================================================
Generated: 2025-10-10T09:30:26.853Z
Workflow File: .github/workflows/checks.yml

======================================================================================
PHASE 1: DEPENDENCY INSTALLATION
======================================================================================

1.1 Frontend Dependencies (pnpm)
Status: âœ“ SUCCESS
- Installed pnpm v10.4.1
- Executed: pnpm install
- Result: 637 packages installed successfully
- Time: ~26 seconds

1.2 Docker Setup
Status: âœ“ SUCCESS
- Docker version: 28.0.4
- Installed docker-compose v2.24.0
- Available services: db, backend, frontend

1.3 Backend Dependencies (pip)
Status: âš  PARTIAL
- Issue encountered: Network timeout while installing numpy==1.24.3
- Root Cause: numpy 1.24.3 is incompatible with Python 3.12
- Error: "AttributeError: module 'pkgutil' has no attribute 'ImpImporter'"
- Recommendation: Update numpy to version >= 1.26.0 for Python 3.12 compatibility

======================================================================================
PHASE 2: WORKFLOW EXECUTION - build-and-test job
======================================================================================

2.1 Fix Locust Version
Status: âœ“ SUCCESS
- Changed locust==2.35.0 to locust==2.20.1 in requirements.txt

2.2 Create Temporary Docker Compose
Status: âœ“ SUCCESS
- Created docker-compose.ci.yml without frontend service
- Services included: db, backend

2.3 Build Database Service
Status: âœ“ SUCCESS  
- Using pre-built image: timescale/timescaledb-ha:pg13-latest
- No build required

2.4 Build Backend Service
Status: âœ— FAILED
- Error: SSL certificate verification failed
- Root Cause: Self-signed certificate in certificate chain
- Impact: Cannot install Python packages from PyPI during Docker build
- Error Message: "[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed"
- Troubleshooting:
  * This is a network/environment issue in the sandboxed environment
  * In production/CI, ensure proper SSL certificates are configured
  * Workaround: Use --trusted-host flag in pip install or configure pip.conf
  * Alternative: Pre-build Docker images or use cached layers

2.5 Start Database and Run Tests
Status: âŠ— SKIPPED
- Reason: Backend build failed, cannot proceed with integration tests

======================================================================================
PHASE 3: WORKFLOW EXECUTION - python-quality-and-security job
======================================================================================

3.1 Setup Python and Install Dependencies
Status: âœ“ SUCCESS
- Python version: 3.12.3
- Installed ruff v0.14.0
- Installed bandit v1.8.6

3.2 Fix Locust Version (Quality Checks)
Status: âœ“ SUCCESS
- Already fixed in previous step

3.3 Run Ruff Linter
Status: âœ“ SUCCESS
- Result: All checks passed!
- No linting errors found in backend code

3.4 Run Bandit Security Scanner
Status: âœ“ SUCCESS
- Scanned backend code excluding test files
- Total issues found: 6
- Severity breakdown:
  * HIGH: 0
  * MEDIUM: 0
  * LOW: 6 (all in test helper scripts)
- Issues Details:
  * All 6 LOW severity issues in ./run_complete_tests.py
  * Related to subprocess module usage (expected in test scripts)
- Generated reports:
  * bandit_report.json (raw JSON output)
  * Would generate bandit_sarif.json for GitHub Security tab

3.5 Upload Security Scan Results
Status: âŠ— SKIPPED
- Reason: Requires GitHub Actions environment to upload SARIF

======================================================================================
PHASE 4: WORKFLOW EXECUTION - dependency-and-secret-scanning job
======================================================================================

4.1 Install and Run Gitleaks
Status: âœ“ SUCCESS
- Installed gitleaks v8.18.1
- Created .gitleaks.toml configuration
- Scan completed in 1.73s
- Result: No leaks found
- All secrets properly excluded via configuration

4.2 Dependency Review
Status: âŠ— SKIPPED
- Reason: Only runs on pull_request events in GitHub Actions

4.3 Run OSV Scanner
Status: âŠ— SKIPPED
- Reason: Requires Go installation and GitHub Actions environment
- Would check for known vulnerabilities in dependencies

======================================================================================
PHASE 5: FRONTEND TESTS EXECUTION
======================================================================================

5.1 Run Frontend Tests (pnpm test)
Status: âš  PARTIAL SUCCESS
- Test framework: Vitest
- Total test files: 6
- Results:
  * Passed tests: 5
  * Failed tests: 1
- Failed test details:
  * File: src/tests/workflow.test.js
  * Test: "Workflow Configuration > should have frontend test step in workflow"
  * Reason: Expected workflow to contain 'Run Frontend Tests' step
  * Root Cause: The workflow has evolved and no longer has a step explicitly
    named "Run Frontend Tests". The workflow now uses Docker-based testing
    which runs backend tests within containers.
  * Fix Required: Update test expectation in workflow.test.js to match current
    workflow structure OR add frontend-specific test step to workflow

- Other tests passed:
  * Workflow file exists âœ“
  * Workflow has valid content âœ“
  * Workflow has required jobs âœ“
  * Package.json exists âœ“
  * Test script configured âœ“
  * Vite config exists âœ“

======================================================================================
SUMMARY OF ERRORS AND ISSUES
======================================================================================

CRITICAL ERRORS (Blocking):
1. Docker Backend Build Failure
   - Component: Backend Docker image build
   - Error: SSL certificate verification failed during pip install
   - Impact: Cannot run backend integration tests in Docker
   - Environment: Sandboxed execution environment
   - Workaround: 
     * Add --trusted-host pypi.org --trusted-host files.pythonhosted.org to pip
     * Configure pip.conf with trusted hosts
     * Use pre-built Docker images
     * In production CI (GitHub Actions), this typically works fine

WARNINGS (Non-blocking):
2. Frontend Test Failure
   - Component: Frontend workflow tests
   - Test: workflow.test.js - "should have frontend test step in workflow"
   - Issue: Test expectation doesn't match current workflow structure
   - Impact: One test fails but doesn't affect functionality
   - Fix: Update test to match current workflow or add frontend test step

3. Python Dependency Installation (Local)
   - Component: Backend requirements.txt
   - Issue: numpy==1.24.3 incompatible with Python 3.12
   - Impact: Cannot install full backend dependencies locally
   - Fix: Update numpy to >=1.26.0 for Python 3.12 compatibility
   - Note: This is fixed in Docker image using Python 3.9

INFORMATIONAL:
4. Low Severity Security Issues
   - Component: Backend test scripts
   - Issue: 6 LOW severity subprocess warnings in run_complete_tests.py
   - Impact: None (expected in test utilities)
   - Action: No action required

======================================================================================
TROUBLESHOOTING RECOMMENDATIONS
======================================================================================

For Local Development:
1. Update requirements.txt for Python 3.12:
   - Change: numpy==1.24.3 -> numpy>=1.26.0
   - Also update scipy and scikit-learn to compatible versions

2. Install dependencies with trusted hosts if SSL issues persist:
   pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org -r requirements.txt

For Docker Build Issues:
1. Modify backend/Dockerfile to add trusted hosts:
   RUN pip install --trusted-host pypi.org --trusted-host files.pythonhosted.org \
       --no-cache-dir -r requirements.txt

2. Or use pre-built base image with dependencies already installed

For CI/CD Pipeline:
1. Update workflow.test.js expectations to match current workflow structure
2. Consider adding explicit frontend test step if desired
3. Ensure GitHub Actions runners have proper SSL certificates (usually automatic)

For Testing:
1. Frontend tests can be run locally with: pnpm test
2. Backend tests require database, best run via Docker Compose
3. Linting and security scans work independently

======================================================================================
WORKFLOW EXECUTION STATISTICS
======================================================================================

Total Steps Attempted: 15
Successful: 9 (60%)
Failed: 1 (7%)
Skipped: 4 (27%)
Partial: 1 (7%)

Execution Time: ~15 minutes
Primary Blocker: SSL certificate verification in sandboxed environment

======================================================================================
CONCLUSION
======================================================================================

The workflow execution reveals that most components are functioning correctly:
âœ“ Frontend dependencies install successfully
âœ“ Code quality checks pass (Ruff linter)
âœ“ Security scanning passes (Bandit, Gitleaks)
âœ“ Most frontend tests pass

The main blocker is the SSL certificate issue in the Docker build environment, which
is specific to the sandboxed execution environment and would not occur in a standard
GitHub Actions runner or local development environment with proper certificates.

The workflow is well-structured and comprehensive, covering:
- Build and integration testing
- Code quality and security scanning
- Dependency and secret scanning
- Automated dependency management

Recommended immediate action:
1. Fix workflow.test.js expectations
2. Update numpy version for Python 3.12 compatibility
3. In production, ensure SSL certificates are properly configured

======================================================================================
END OF REPORT
======================================================================================
Generated: 2025-10-10T09:53:00.000Z

#0 building with "default" instance using docker driver

#1 [backend internal] load build definition from Dockerfile
#1 transferring dockerfile: 767B done
#1 DONE 0.0s

#2 [backend auth] library/python:pull token for registry-1.docker.io
#2 DONE 0.0s

#3 [backend internal] load metadata for docker.io/library/python:3.9-slim-bullseye
#3 DONE 0.7s

#4 [backend internal] load .dockerignore
#4 transferring context: 725B done
#4 DONE 0.0s

#5 [backend internal] load build context
#5 transferring context: 2.36MB 0.0s done
#5 DONE 0.0s

#6 [backend 1/7] FROM docker.io/library/python:3.9-slim-bullseye@sha256:b9e06687fbfc57f6fe563e94e4c8751e39513dde89afc120dc6f56afe5ffc761
#6 resolve docker.io/library/python:3.9-slim-bullseye@sha256:b9e06687fbfc57f6fe563e94e4c8751e39513dde89afc120dc6f56afe5ffc761 done
#6 sha256:ed6f8d42e44570055a5b6c16df05ff3ad5d129ce4a3bfc8baefad15949952a3f 5.29kB / 5.29kB done
#6 sha256:ccaf924377f936af2c0396fce237145b7d1ecc0b8196916667fc6d5ff4866e2d 6.49MB / 30.26MB 0.1s
#6 sha256:41552ab592e76c41784983dfa0ce81756adf23003bf5fd2b3cfcd85b8ea7cf14 0B / 1.08MB 0.1s
#6 sha256:204f9764bd9cde668ca81622b2652247d139b76c965c1ace64be2d2622890d1a 1.05MB / 14.13MB 0.1s
#6 sha256:b9e06687fbfc57f6fe563e94e4c8751e39513dde89afc120dc6f56afe5ffc761 5.25kB / 5.25kB done
#6 sha256:2d9d670c924fc332b15d9565e24a2b76ba781e51ea3eb8305ccbf7c86f3f88be 1.75kB / 1.75kB done
#6 sha256:ccaf924377f936af2c0396fce237145b7d1ecc0b8196916667fc6d5ff4866e2d 18.87MB / 30.26MB 0.2s
#6 sha256:41552ab592e76c41784983dfa0ce81756adf23003bf5fd2b3cfcd85b8ea7cf14 1.08MB / 1.08MB 0.1s done
#6 sha256:204f9764bd9cde668ca81622b2652247d139b76c965c1ace64be2d2622890d1a 13.63MB / 14.13MB 0.2s
#6 sha256:7006e6b111bd7d707617436bd7900d8e831c3f9ef79886fc065c1c269a73cff1 250B / 250B 0.2s done
#6 sha256:ccaf924377f936af2c0396fce237145b7d1ecc0b8196916667fc6d5ff4866e2d 30.26MB / 30.26MB 0.3s done
#6 sha256:204f9764bd9cde668ca81622b2652247d139b76c965c1ace64be2d2622890d1a 14.13MB / 14.13MB 0.3s done
#6 extracting sha256:ccaf924377f936af2c0396fce237145b7d1ecc0b8196916667fc6d5ff4866e2d 0.1s
#6 extracting sha256:ccaf924377f936af2c0396fce237145b7d1ecc0b8196916667fc6d5ff4866e2d 1.1s done
#6 extracting sha256:41552ab592e76c41784983dfa0ce81756adf23003bf5fd2b3cfcd85b8ea7cf14 0.1s done
#6 extracting sha256:204f9764bd9cde668ca81622b2652247d139b76c965c1ace64be2d2622890d1a
#6 extracting sha256:204f9764bd9cde668ca81622b2652247d139b76c965c1ace64be2d2622890d1a 0.6s done
#6 extracting sha256:7006e6b111bd7d707617436bd7900d8e831c3f9ef79886fc065c1c269a73cff1 done
#6 DONE 2.3s

#7 [backend 2/7] WORKDIR /app
#7 DONE 0.0s

#8 [backend 3/7] RUN apt-get update && apt-get install -y     libpq-dev     gcc     && rm -rf /var/lib/apt/lists/*
#8 0.221 Get:1 http://deb.debian.org/debian bullseye InRelease [75.1 kB]
#8 0.286 Get:2 http://deb.debian.org/debian-security bullseye-security InRelease [27.2 kB]
#8 0.343 Get:3 http://deb.debian.org/debian bullseye-updates InRelease [44.0 kB]
#8 0.401 Get:4 http://deb.debian.org/debian bullseye/main amd64 Packages [8066 kB]
#8 0.530 Get:5 http://deb.debian.org/debian-security bullseye-security/main amd64 Packages [411 kB]
#8 0.615 Get:6 http://deb.debian.org/debian bullseye-updates/main amd64 Packages [18.8 kB]
#8 1.330 Fetched 8642 kB in 1s (7318 kB/s)
#8 1.330 Reading package lists...
#8 1.706 Reading package lists...
#8 2.068 Building dependency tree...
#8 2.149 Reading state information...
#8 2.232 The following additional packages will be installed:
#8 2.232   binutils binutils-common binutils-x86-64-linux-gnu cpp cpp-10
#8 2.232   fontconfig-config fonts-dejavu-core gcc-10 libasan6 libatomic1 libbinutils
#8 2.232   libbrotli1 libbsd0 libc-dev-bin libc-devtools libc6-dev libcc1-0
#8 2.232   libcrypt-dev libctf-nobfd0 libctf0 libdeflate0 libexpat1 libfontconfig1
#8 2.232   libfreetype6 libgcc-10-dev libgd3 libgomp1 libisl23 libitm1 libjbig0
#8 2.232   libjpeg62-turbo libldap-2.4-2 libldap-common liblsan0 libmd0 libmpc3
#8 2.232   libmpfr6 libnsl-dev libpng16-16 libpq5 libquadmath0 libsasl2-2
#8 2.232   libsasl2-modules libsasl2-modules-db libtiff5 libtirpc-dev libtsan0
#8 2.232   libubsan1 libwebp6 libx11-6 libx11-data libxau6 libxcb1 libxdmcp6 libxpm4
#8 2.232   linux-libc-dev manpages manpages-dev sensible-utils ucf
#8 2.233 Suggested packages:
#8 2.233   binutils-doc cpp-doc gcc-10-locales gcc-multilib make autoconf automake
#8 2.233   libtool flex bison gdb gcc-doc gcc-10-multilib gcc-10-doc glibc-doc
#8 2.233   libgd-tools postgresql-doc-13 libsasl2-modules-gssapi-mit
#8 2.233   | libsasl2-modules-gssapi-heimdal libsasl2-modules-ldap libsasl2-modules-otp
#8 2.233   libsasl2-modules-sql man-browser
#8 2.439 The following NEW packages will be installed:
#8 2.439   binutils binutils-common binutils-x86-64-linux-gnu cpp cpp-10
#8 2.440   fontconfig-config fonts-dejavu-core gcc gcc-10 libasan6 libatomic1
#8 2.440   libbinutils libbrotli1 libbsd0 libc-dev-bin libc-devtools libc6-dev libcc1-0
#8 2.440   libcrypt-dev libctf-nobfd0 libctf0 libdeflate0 libexpat1 libfontconfig1
#8 2.440   libfreetype6 libgcc-10-dev libgd3 libgomp1 libisl23 libitm1 libjbig0
#8 2.440   libjpeg62-turbo libldap-2.4-2 libldap-common liblsan0 libmd0 libmpc3
#8 2.440   libmpfr6 libnsl-dev libpng16-16 libpq-dev libpq5 libquadmath0 libsasl2-2
#8 2.440   libsasl2-modules libsasl2-modules-db libtiff5 libtirpc-dev libtsan0
#8 2.440   libubsan1 libwebp6 libx11-6 libx11-data libxau6 libxcb1 libxdmcp6 libxpm4
#8 2.440   linux-libc-dev manpages manpages-dev sensible-utils ucf
#8 2.506 0 upgraded, 62 newly installed, 0 to remove and 9 not upgraded.
#8 2.506 Need to get 56.4 MB of archives.
#8 2.506 After this operation, 196 MB of additional disk space will be used.
#8 2.506 Get:1 http://deb.debian.org/debian bullseye/main amd64 sensible-utils all 0.0.14 [14.8 kB]
#8 2.560 Get:2 http://deb.debian.org/debian bullseye/main amd64 manpages all 5.10-1 [1412 kB]
#8 2.609 Get:3 http://deb.debian.org/debian-security bullseye-security/main amd64 ucf all 3.0043+deb11u2 [74.3 kB]
#8 2.653 Get:4 http://deb.debian.org/debian bullseye/main amd64 binutils-common amd64 2.35.2-2 [2220 kB]
#8 2.710 Get:5 http://deb.debian.org/debian bullseye/main amd64 libbinutils amd64 2.35.2-2 [570 kB]
#8 2.763 Get:6 http://deb.debian.org/debian bullseye/main amd64 libctf-nobfd0 amd64 2.35.2-2 [110 kB]
#8 2.816 Get:7 http://deb.debian.org/debian bullseye/main amd64 libctf0 amd64 2.35.2-2 [53.2 kB]
#8 2.862 Get:8 http://deb.debian.org/debian bullseye/main amd64 binutils-x86-64-linux-gnu amd64 2.35.2-2 [1809 kB]
#8 2.920 Get:9 http://deb.debian.org/debian bullseye/main amd64 binutils amd64 2.35.2-2 [61.2 kB]
#8 2.972 Get:10 http://deb.debian.org/debian bullseye/main amd64 libisl23 amd64 0.23-1 [676 kB]
#8 3.019 Get:11 http://deb.debian.org/debian bullseye/main amd64 libmpfr6 amd64 4.1.0-3 [2012 kB]
#8 3.086 Get:12 http://deb.debian.org/debian bullseye/main amd64 libmpc3 amd64 1.2.0-1 [45.0 kB]
#8 3.129 Get:13 http://deb.debian.org/debian bullseye/main amd64 cpp-10 amd64 10.2.1-6 [8528 kB]
#8 3.220 Get:14 http://deb.debian.org/debian bullseye/main amd64 cpp amd64 4:10.2.1-1 [19.7 kB]
#8 3.267 Get:15 http://deb.debian.org/debian bullseye/main amd64 fonts-dejavu-core all 2.37-2 [1069 kB]
#8 3.323 Get:16 http://deb.debian.org/debian bullseye/main amd64 fontconfig-config all 2.13.1-4.2 [281 kB]
#8 3.369 Get:17 http://deb.debian.org/debian bullseye/main amd64 libcc1-0 amd64 10.2.1-6 [47.0 kB]
#8 3.416 Get:18 http://deb.debian.org/debian bullseye/main amd64 libgomp1 amd64 10.2.1-6 [99.9 kB]
#8 3.465 Get:19 http://deb.debian.org/debian bullseye/main amd64 libitm1 amd64 10.2.1-6 [25.8 kB]
#8 3.510 Get:20 http://deb.debian.org/debian bullseye/main amd64 libatomic1 amd64 10.2.1-6 [9008 B]
#8 3.557 Get:21 http://deb.debian.org/debian bullseye/main amd64 libasan6 amd64 10.2.1-6 [2065 kB]
#8 3.610 Get:22 http://deb.debian.org/debian bullseye/main amd64 liblsan0 amd64 10.2.1-6 [828 kB]
#8 3.668 Get:23 http://deb.debian.org/debian bullseye/main amd64 libtsan0 amd64 10.2.1-6 [2000 kB]
#8 3.730 Get:24 http://deb.debian.org/debian bullseye/main amd64 libubsan1 amd64 10.2.1-6 [777 kB]
#8 3.776 Get:25 http://deb.debian.org/debian bullseye/main amd64 libquadmath0 amd64 10.2.1-6 [145 kB]
#8 3.822 Get:26 http://deb.debian.org/debian bullseye/main amd64 libgcc-10-dev amd64 10.2.1-6 [2328 kB]
#8 3.878 Get:27 http://deb.debian.org/debian bullseye/main amd64 gcc-10 amd64 10.2.1-6 [17.0 MB]
#8 3.994 Get:28 http://deb.debian.org/debian bullseye/main amd64 gcc amd64 4:10.2.1-1 [5192 B]
#8 4.040 Get:29 http://deb.debian.org/debian bullseye/main amd64 libbrotli1 amd64 1.0.9-2+b2 [279 kB]
#8 4.090 Get:30 http://deb.debian.org/debian bullseye/main amd64 libmd0 amd64 1.0.3-3 [28.0 kB]
#8 4.141 Get:31 http://deb.debian.org/debian bullseye/main amd64 libbsd0 amd64 0.11.3-1+deb11u1 [108 kB]
#8 4.188 Get:32 http://deb.debian.org/debian-security bullseye-security/main amd64 libc-dev-bin amd64 2.31-13+deb11u13 [277 kB]
#8 4.236 Get:33 http://deb.debian.org/debian-security bullseye-security/main amd64 libexpat1 amd64 2.2.10-2+deb11u7 [99.2 kB]
#8 4.287 Get:34 http://deb.debian.org/debian bullseye/main amd64 libpng16-16 amd64 1.6.37-3 [294 kB]
#8 4.334 Get:35 http://deb.debian.org/debian-security bullseye-security/main amd64 libfreetype6 amd64 2.10.4+dfsg-1+deb11u2 [418 kB]
#8 4.381 Get:36 http://deb.debian.org/debian bullseye/main amd64 libfontconfig1 amd64 2.13.1-4.2 [347 kB]
#8 4.425 Get:37 http://deb.debian.org/debian bullseye/main amd64 libjpeg62-turbo amd64 1:2.0.6-4 [151 kB]
#8 4.473 Get:38 http://deb.debian.org/debian bullseye/main amd64 libdeflate0 amd64 1.7-1 [53.1 kB]
#8 4.522 Get:39 http://deb.debian.org/debian bullseye/main amd64 libjbig0 amd64 2.1-3.1+b2 [31.0 kB]
#8 4.571 Get:40 http://deb.debian.org/debian bullseye/main amd64 libwebp6 amd64 0.6.1-2.1+deb11u2 [259 kB]
#8 4.620 Get:41 http://deb.debian.org/debian-security bullseye-security/main amd64 libtiff5 amd64 4.2.0-1+deb11u7 [291 kB]
#8 4.670 Get:42 http://deb.debian.org/debian bullseye/main amd64 libxau6 amd64 1:1.0.9-1 [19.7 kB]
#8 4.721 Get:43 http://deb.debian.org/debian bullseye/main amd64 libxdmcp6 amd64 1:1.1.2-3 [26.3 kB]
#8 4.770 Get:44 http://deb.debian.org/debian bullseye/main amd64 libxcb1 amd64 1.14-3 [140 kB]
#8 4.816 Get:45 http://deb.debian.org/debian bullseye/main amd64 libx11-data all 2:1.7.2-1+deb11u2 [311 kB]
#8 4.867 Get:46 http://deb.debian.org/debian bullseye/main amd64 libx11-6 amd64 2:1.7.2-1+deb11u2 [772 kB]
#8 4.925 Get:47 http://deb.debian.org/debian bullseye/main amd64 libxpm4 amd64 1:3.5.12-1.1+deb11u1 [50.0 kB]
#8 4.968 Get:48 http://deb.debian.org/debian bullseye/main amd64 libgd3 amd64 2.3.0-2 [137 kB]
#8 5.014 Get:49 http://deb.debian.org/debian-security bullseye-security/main amd64 libc-devtools amd64 2.31-13+deb11u13 [247 kB]
#8 5.070 Get:50 http://deb.debian.org/debian-security bullseye-security/main amd64 linux-libc-dev amd64 5.10.237-1 [1820 kB]
#8 5.128 Get:51 http://deb.debian.org/debian bullseye/main amd64 libcrypt-dev amd64 1:4.4.18-4 [104 kB]
#8 5.176 Get:52 http://deb.debian.org/debian bullseye/main amd64 libtirpc-dev amd64 1.3.1-1+deb11u1 [191 kB]
#8 5.220 Get:53 http://deb.debian.org/debian bullseye/main amd64 libnsl-dev amd64 1.3.0-2 [66.4 kB]
#8 5.269 Get:54 http://deb.debian.org/debian-security bullseye-security/main amd64 libc6-dev amd64 2.31-13+deb11u13 [2362 kB]
#8 5.338 Get:55 http://deb.debian.org/debian bullseye/main amd64 libsasl2-modules-db amd64 2.1.27+dfsg-2.1+deb11u1 [69.1 kB]
#8 5.386 Get:56 http://deb.debian.org/debian bullseye/main amd64 libsasl2-2 amd64 2.1.27+dfsg-2.1+deb11u1 [106 kB]
#8 5.439 Get:57 http://deb.debian.org/debian bullseye/main amd64 libldap-2.4-2 amd64 2.4.57+dfsg-3+deb11u1 [232 kB]
#8 5.493 Get:58 http://deb.debian.org/debian bullseye/main amd64 libldap-common all 2.4.57+dfsg-3+deb11u1 [95.8 kB]
#8 5.541 Get:59 http://deb.debian.org/debian-security bullseye-security/main amd64 libpq5 amd64 13.22-0+deb11u1 [187 kB]
#8 5.586 Get:60 http://deb.debian.org/debian-security bullseye-security/main amd64 libpq-dev amd64 13.22-0+deb11u1 [146 kB]
#8 5.628 Get:61 http://deb.debian.org/debian bullseye/main amd64 libsasl2-modules amd64 2.1.27+dfsg-2.1+deb11u1 [104 kB]
#8 5.678 Get:62 http://deb.debian.org/debian bullseye/main amd64 manpages-dev all 5.10-1 [2309 kB]
#8 5.777 debconf: delaying package configuration, since apt-utils is not installed
#8 5.798 Fetched 56.4 MB in 3s (17.4 MB/s)
#8 5.811 Selecting previously unselected package sensible-utils.
#8 5.811 (Reading database ... (Reading database ... 5%(Reading database ... 10%(Reading database ... 15%(Reading database ... 20%(Reading database ... 25%(Reading database ... 30%(Reading database ... 35%(Reading database ... 40%(Reading database ... 45%(Reading database ... 50%(Reading database ... 55%(Reading database ... 60%(Reading database ... 65%(Reading database ... 70%(Reading database ... 75%(Reading database ... 80%(Reading database ... 85%(Reading database ... 90%(Reading database ... 95%(Reading database ... 100%(Reading database ... 7034 files and directories currently installed.)
#8 5.817 Preparing to unpack .../00-sensible-utils_0.0.14_all.deb ...
#8 5.818 Unpacking sensible-utils (0.0.14) ...
#8 5.837 Selecting previously unselected package manpages.
#8 5.837 Preparing to unpack .../01-manpages_5.10-1_all.deb ...
#8 5.839 Unpacking manpages (5.10-1) ...
#8 5.926 Selecting previously unselected package ucf.
#8 5.927 Preparing to unpack .../02-ucf_3.0043+deb11u2_all.deb ...
#8 5.929 Moving old data out of the way
#8 5.931 Unpacking ucf (3.0043+deb11u2) ...
#8 5.948 Selecting previously unselected package binutils-common:amd64.
#8 5.949 Preparing to unpack .../03-binutils-common_2.35.2-2_amd64.deb ...
#8 5.950 Unpacking binutils-common:amd64 (2.35.2-2) ...
#8 6.116 Selecting previously unselected package libbinutils:amd64.
#8 6.117 Preparing to unpack .../04-libbinutils_2.35.2-2_amd64.deb ...
#8 6.119 Unpacking libbinutils:amd64 (2.35.2-2) ...
#8 6.175 Selecting previously unselected package libctf-nobfd0:amd64.
#8 6.176 Preparing to unpack .../05-libctf-nobfd0_2.35.2-2_amd64.deb ...
#8 6.177 Unpacking libctf-nobfd0:amd64 (2.35.2-2) ...
#8 6.198 Selecting previously unselected package libctf0:amd64.
#8 6.199 Preparing to unpack .../06-libctf0_2.35.2-2_amd64.deb ...
#8 6.200 Unpacking libctf0:amd64 (2.35.2-2) ...
#8 6.216 Selecting previously unselected package binutils-x86-64-linux-gnu.
#8 6.217 Preparing to unpack .../07-binutils-x86-64-linux-gnu_2.35.2-2_amd64.deb ...
#8 6.218 Unpacking binutils-x86-64-linux-gnu (2.35.2-2) ...
#8 6.386 Selecting previously unselected package binutils.
#8 6.387 Preparing to unpack .../08-binutils_2.35.2-2_amd64.deb ...
#8 6.388 Unpacking binutils (2.35.2-2) ...
#8 6.410 Selecting previously unselected package libisl23:amd64.
#8 6.411 Preparing to unpack .../09-libisl23_0.23-1_amd64.deb ...
#8 6.412 Unpacking libisl23:amd64 (0.23-1) ...
#8 6.476 Selecting previously unselected package libmpfr6:amd64.
#8 6.477 Preparing to unpack .../10-libmpfr6_4.1.0-3_amd64.deb ...
#8 6.478 Unpacking libmpfr6:amd64 (4.1.0-3) ...
#8 6.564 Selecting previously unselected package libmpc3:amd64.
#8 6.566 Preparing to unpack .../11-libmpc3_1.2.0-1_amd64.deb ...
#8 6.567 Unpacking libmpc3:amd64 (1.2.0-1) ...
#8 6.583 Selecting previously unselected package cpp-10.
#8 6.584 Preparing to unpack .../12-cpp-10_10.2.1-6_amd64.deb ...
#8 6.584 Unpacking cpp-10 (10.2.1-6) ...
#8 7.124 Selecting previously unselected package cpp.
#8 7.126 Preparing to unpack .../13-cpp_4%3a10.2.1-1_amd64.deb ...
#8 7.127 Unpacking cpp (4:10.2.1-1) ...
#8 7.142 Selecting previously unselected package fonts-dejavu-core.
#8 7.143 Preparing to unpack .../14-fonts-dejavu-core_2.37-2_all.deb ...
#8 7.144 Unpacking fonts-dejavu-core (2.37-2) ...
#8 7.236 Selecting previously unselected package fontconfig-config.
#8 7.237 Preparing to unpack .../15-fontconfig-config_2.13.1-4.2_all.deb ...
#8 7.338 Unpacking fontconfig-config (2.13.1-4.2) ...
#8 7.366 Selecting previously unselected package libcc1-0:amd64.
#8 7.368 Preparing to unpack .../16-libcc1-0_10.2.1-6_amd64.deb ...
#8 7.369 Unpacking libcc1-0:amd64 (10.2.1-6) ...
#8 7.386 Selecting previously unselected package libgomp1:amd64.
#8 7.387 Preparing to unpack .../17-libgomp1_10.2.1-6_amd64.deb ...
#8 7.388 Unpacking libgomp1:amd64 (10.2.1-6) ...
#8 7.409 Selecting previously unselected package libitm1:amd64.
#8 7.410 Preparing to unpack .../18-libitm1_10.2.1-6_amd64.deb ...
#8 7.411 Unpacking libitm1:amd64 (10.2.1-6) ...
#8 7.428 Selecting previously unselected package libatomic1:amd64.
#8 7.429 Preparing to unpack .../19-libatomic1_10.2.1-6_amd64.deb ...
#8 7.430 Unpacking libatomic1:amd64 (10.2.1-6) ...
#8 7.444 Selecting previously unselected package libasan6:amd64.
#8 7.445 Preparing to unpack .../20-libasan6_10.2.1-6_amd64.deb ...
#8 7.446 Unpacking libasan6:amd64 (10.2.1-6) ...
#8 7.604 Selecting previously unselected package liblsan0:amd64.
#8 7.605 Preparing to unpack .../21-liblsan0_10.2.1-6_amd64.deb ...
#8 7.607 Unpacking liblsan0:amd64 (10.2.1-6) ...
#8 7.676 Selecting previously unselected package libtsan0:amd64.
#8 7.677 Preparing to unpack .../22-libtsan0_10.2.1-6_amd64.deb ...
#8 7.679 Unpacking libtsan0:amd64 (10.2.1-6) ...
#8 7.853 Selecting previously unselected package libubsan1:amd64.
#8 7.854 Preparing to unpack .../23-libubsan1_10.2.1-6_amd64.deb ...
#8 7.855 Unpacking libubsan1:amd64 (10.2.1-6) ...
#8 7.927 Selecting previously unselected package libquadmath0:amd64.
#8 7.928 Preparing to unpack .../24-libquadmath0_10.2.1-6_amd64.deb ...
#8 7.929 Unpacking libquadmath0:amd64 (10.2.1-6) ...
#8 7.952 Selecting previously unselected package libgcc-10-dev:amd64.
#8 7.953 Preparing to unpack .../25-libgcc-10-dev_10.2.1-6_amd64.deb ...
#8 7.954 Unpacking libgcc-10-dev:amd64 (10.2.1-6) ...
#8 8.127 Selecting previously unselected package gcc-10.
#8 8.128 Preparing to unpack .../26-gcc-10_10.2.1-6_amd64.deb ...
#8 8.129 Unpacking gcc-10 (10.2.1-6) ...
#8 9.190 Selecting previously unselected package gcc.
#8 9.191 Preparing to unpack .../27-gcc_4%3a10.2.1-1_amd64.deb ...
#8 9.192 Unpacking gcc (4:10.2.1-1) ...
#8 9.209 Selecting previously unselected package libbrotli1:amd64.
#8 9.210 Preparing to unpack .../28-libbrotli1_1.0.9-2+b2_amd64.deb ...
#8 9.211 Unpacking libbrotli1:amd64 (1.0.9-2+b2) ...
#8 9.245 Selecting previously unselected package libmd0:amd64.
#8 9.246 Preparing to unpack .../29-libmd0_1.0.3-3_amd64.deb ...
#8 9.247 Unpacking libmd0:amd64 (1.0.3-3) ...
#8 9.263 Selecting previously unselected package libbsd0:amd64.
#8 9.264 Preparing to unpack .../30-libbsd0_0.11.3-1+deb11u1_amd64.deb ...
#8 9.265 Unpacking libbsd0:amd64 (0.11.3-1+deb11u1) ...
#8 9.285 Selecting previously unselected package libc-dev-bin.
#8 9.286 Preparing to unpack .../31-libc-dev-bin_2.31-13+deb11u13_amd64.deb ...
#8 9.287 Unpacking libc-dev-bin (2.31-13+deb11u13) ...
#8 9.307 Selecting previously unselected package libexpat1:amd64.
#8 9.308 Preparing to unpack .../32-libexpat1_2.2.10-2+deb11u7_amd64.deb ...
#8 9.309 Unpacking libexpat1:amd64 (2.2.10-2+deb11u7) ...
#8 9.331 Selecting previously unselected package libpng16-16:amd64.
#8 9.332 Preparing to unpack .../33-libpng16-16_1.6.37-3_amd64.deb ...
#8 9.333 Unpacking libpng16-16:amd64 (1.6.37-3) ...
#8 9.364 Selecting previously unselected package libfreetype6:amd64.
#8 9.365 Preparing to unpack .../34-libfreetype6_2.10.4+dfsg-1+deb11u2_amd64.deb ...
#8 9.366 Unpacking libfreetype6:amd64 (2.10.4+dfsg-1+deb11u2) ...
#8 9.412 Selecting previously unselected package libfontconfig1:amd64.
#8 9.413 Preparing to unpack .../35-libfontconfig1_2.13.1-4.2_amd64.deb ...
#8 9.414 Unpacking libfontconfig1:amd64 (2.13.1-4.2) ...
#8 9.438 Selecting previously unselected package libjpeg62-turbo:amd64.
#8 9.439 Preparing to unpack .../36-libjpeg62-turbo_1%3a2.0.6-4_amd64.deb ...
#8 9.440 Unpacking libjpeg62-turbo:amd64 (1:2.0.6-4) ...
#8 9.465 Selecting previously unselected package libdeflate0:amd64.
#8 9.466 Preparing to unpack .../37-libdeflate0_1.7-1_amd64.deb ...
#8 9.467 Unpacking libdeflate0:amd64 (1.7-1) ...
#8 9.484 Selecting previously unselected package libjbig0:amd64.
#8 9.485 Preparing to unpack .../38-libjbig0_2.1-3.1+b2_amd64.deb ...
#8 9.486 Unpacking libjbig0:amd64 (2.1-3.1+b2) ...
#8 9.503 Selecting previously unselected package libwebp6:amd64.
#8 9.504 Preparing to unpack .../39-libwebp6_0.6.1-2.1+deb11u2_amd64.deb ...
#8 9.505 Unpacking libwebp6:amd64 (0.6.1-2.1+deb11u2) ...
#8 9.534 Selecting previously unselected package libtiff5:amd64.
#8 9.535 Preparing to unpack .../40-libtiff5_4.2.0-1+deb11u7_amd64.deb ...
#8 9.536 Unpacking libtiff5:amd64 (4.2.0-1+deb11u7) ...
#8 9.567 Selecting previously unselected package libxau6:amd64.
#8 9.568 Preparing to unpack .../41-libxau6_1%3a1.0.9-1_amd64.deb ...
#8 9.569 Unpacking libxau6:amd64 (1:1.0.9-1) ...
#8 9.584 Selecting previously unselected package libxdmcp6:amd64.
#8 9.585 Preparing to unpack .../42-libxdmcp6_1%3a1.1.2-3_amd64.deb ...
#8 9.586 Unpacking libxdmcp6:amd64 (1:1.1.2-3) ...
#8 9.602 Selecting previously unselected package libxcb1:amd64.
#8 9.603 Preparing to unpack .../43-libxcb1_1.14-3_amd64.deb ...
#8 9.604 Unpacking libxcb1:amd64 (1.14-3) ...
#8 9.624 Selecting previously unselected package libx11-data.
#8 9.625 Preparing to unpack .../44-libx11-data_2%3a1.7.2-1+deb11u2_all.deb ...
#8 9.626 Unpacking libx11-data (2:1.7.2-1+deb11u2) ...
#8 9.683 Selecting previously unselected package libx11-6:amd64.
#8 9.684 Preparing to unpack .../45-libx11-6_2%3a1.7.2-1+deb11u2_amd64.deb ...
#8 9.685 Unpacking libx11-6:amd64 (2:1.7.2-1+deb11u2) ...
#8 9.741 Selecting previously unselected package libxpm4:amd64.
#8 9.742 Preparing to unpack .../46-libxpm4_1%3a3.5.12-1.1+deb11u1_amd64.deb ...
#8 9.743 Unpacking libxpm4:amd64 (1:3.5.12-1.1+deb11u1) ...
#8 9.760 Selecting previously unselected package libgd3:amd64.
#8 9.761 Preparing to unpack .../47-libgd3_2.3.0-2_amd64.deb ...
#8 9.762 Unpacking libgd3:amd64 (2.3.0-2) ...
#8 9.784 Selecting previously unselected package libc-devtools.
#8 9.785 Preparing to unpack .../48-libc-devtools_2.31-13+deb11u13_amd64.deb ...
#8 9.786 Unpacking libc-devtools (2.31-13+deb11u13) ...
#8 9.807 Selecting previously unselected package linux-libc-dev:amd64.
#8 9.809 Preparing to unpack .../49-linux-libc-dev_5.10.237-1_amd64.deb ...
#8 9.809 Unpacking linux-libc-dev:amd64 (5.10.237-1) ...
#8 9.987 Selecting previously unselected package libcrypt-dev:amd64.
#8 9.988 Preparing to unpack .../50-libcrypt-dev_1%3a4.4.18-4_amd64.deb ...
#8 9.989 Unpacking libcrypt-dev:amd64 (1:4.4.18-4) ...
#8 10.01 Selecting previously unselected package libtirpc-dev:amd64.
#8 10.01 Preparing to unpack .../51-libtirpc-dev_1.3.1-1+deb11u1_amd64.deb ...
#8 10.01 Unpacking libtirpc-dev:amd64 (1.3.1-1+deb11u1) ...
#8 10.04 Selecting previously unselected package libnsl-dev:amd64.
#8 10.04 Preparing to unpack .../52-libnsl-dev_1.3.0-2_amd64.deb ...
#8 10.04 Unpacking libnsl-dev:amd64 (1.3.0-2) ...
#8 10.06 Selecting previously unselected package libc6-dev:amd64.
#8 10.06 Preparing to unpack .../53-libc6-dev_2.31-13+deb11u13_amd64.deb ...
#8 10.06 Unpacking libc6-dev:amd64 (2.31-13+deb11u13) ...
#8 10.29 Selecting previously unselected package libsasl2-modules-db:amd64.
#8 10.29 Preparing to unpack .../54-libsasl2-modules-db_2.1.27+dfsg-2.1+deb11u1_amd64.deb ...
#8 10.29 Unpacking libsasl2-modules-db:amd64 (2.1.27+dfsg-2.1+deb11u1) ...
#8 10.31 Selecting previously unselected package libsasl2-2:amd64.
#8 10.31 Preparing to unpack .../55-libsasl2-2_2.1.27+dfsg-2.1+deb11u1_amd64.deb ...
#8 10.31 Unpacking libsasl2-2:amd64 (2.1.27+dfsg-2.1+deb11u1) ...
#8 10.33 Selecting previously unselected package libldap-2.4-2:amd64.
#8 10.34 Preparing to unpack .../56-libldap-2.4-2_2.4.57+dfsg-3+deb11u1_amd64.deb ...
#8 10.34 Unpacking libldap-2.4-2:amd64 (2.4.57+dfsg-3+deb11u1) ...
#8 10.37 Selecting previously unselected package libldap-common.
#8 10.37 Preparing to unpack .../57-libldap-common_2.4.57+dfsg-3+deb11u1_all.deb ...
#8 10.37 Unpacking libldap-common (2.4.57+dfsg-3+deb11u1) ...
#8 10.39 Selecting previously unselected package libpq5:amd64.
#8 10.39 Preparing to unpack .../58-libpq5_13.22-0+deb11u1_amd64.deb ...
#8 10.39 Unpacking libpq5:amd64 (13.22-0+deb11u1) ...
#8 10.42 Selecting previously unselected package libpq-dev.
#8 10.42 Preparing to unpack .../59-libpq-dev_13.22-0+deb11u1_amd64.deb ...
#8 10.42 Unpacking libpq-dev (13.22-0+deb11u1) ...
#8 10.45 Selecting previously unselected package libsasl2-modules:amd64.
#8 10.45 Preparing to unpack .../60-libsasl2-modules_2.1.27+dfsg-2.1+deb11u1_amd64.deb ...
#8 10.45 Unpacking libsasl2-modules:amd64 (2.1.27+dfsg-2.1+deb11u1) ...
#8 10.47 Selecting previously unselected package manpages-dev.
#8 10.47 Preparing to unpack .../61-manpages-dev_5.10-1_all.deb ...
#8 10.47 Unpacking manpages-dev (5.10-1) ...
#8 10.67 Setting up libexpat1:amd64 (2.2.10-2+deb11u7) ...
#8 10.68 Setting up libxau6:amd64 (1:1.0.9-1) ...
#8 10.68 Setting up manpages (5.10-1) ...
#8 10.68 Setting up libbrotli1:amd64 (1.0.9-2+b2) ...
#8 10.68 Setting up libsasl2-modules:amd64 (2.1.27+dfsg-2.1+deb11u1) ...
#8 10.69 Setting up binutils-common:amd64 (2.35.2-2) ...
#8 10.69 Setting up libdeflate0:amd64 (1.7-1) ...
#8 10.69 Setting up linux-libc-dev:amd64 (5.10.237-1) ...
#8 10.70 Setting up libctf-nobfd0:amd64 (2.35.2-2) ...
#8 10.70 Setting up libgomp1:amd64 (10.2.1-6) ...
#8 10.70 Setting up libldap-common (2.4.57+dfsg-3+deb11u1) ...
#8 10.71 Setting up libjbig0:amd64 (2.1-3.1+b2) ...
#8 10.71 Setting up libasan6:amd64 (10.2.1-6) ...
#8 10.71 Setting up libsasl2-modules-db:amd64 (2.1.27+dfsg-2.1+deb11u1) ...
#8 10.71 Setting up libtirpc-dev:amd64 (1.3.1-1+deb11u1) ...
#8 10.72 Setting up libjpeg62-turbo:amd64 (1:2.0.6-4) ...
#8 10.72 Setting up libx11-data (2:1.7.2-1+deb11u2) ...
#8 10.72 Setting up libmpfr6:amd64 (4.1.0-3) ...
#8 10.72 Setting up libquadmath0:amd64 (10.2.1-6) ...
#8 10.73 Setting up libpng16-16:amd64 (1.6.37-3) ...
#8 10.73 Setting up libmpc3:amd64 (1.2.0-1) ...
#8 10.73 Setting up libatomic1:amd64 (10.2.1-6) ...
#8 10.73 Setting up libwebp6:amd64 (0.6.1-2.1+deb11u2) ...
#8 10.74 Setting up fonts-dejavu-core (2.37-2) ...
#8 10.75 Setting up libsasl2-2:amd64 (2.1.27+dfsg-2.1+deb11u1) ...
#8 10.75 Setting up libubsan1:amd64 (10.2.1-6) ...
#8 10.75 Setting up libmd0:amd64 (1.0.3-3) ...
#8 10.76 Setting up libnsl-dev:amd64 (1.3.0-2) ...
#8 10.76 Setting up sensible-utils (0.0.14) ...
#8 10.76 Setting up libcrypt-dev:amd64 (1:4.4.18-4) ...
#8 10.76 Setting up libtiff5:amd64 (4.2.0-1+deb11u7) ...
#8 10.77 Setting up libbinutils:amd64 (2.35.2-2) ...
#8 10.77 Setting up libisl23:amd64 (0.23-1) ...
#8 10.77 Setting up libc-dev-bin (2.31-13+deb11u13) ...
#8 10.77 Setting up libbsd0:amd64 (0.11.3-1+deb11u1) ...
#8 10.78 Setting up libcc1-0:amd64 (10.2.1-6) ...
#8 10.78 Setting up liblsan0:amd64 (10.2.1-6) ...
#8 10.78 Setting up cpp-10 (10.2.1-6) ...
#8 10.78 Setting up libitm1:amd64 (10.2.1-6) ...
#8 10.79 Setting up libtsan0:amd64 (10.2.1-6) ...
#8 10.79 Setting up libctf0:amd64 (2.35.2-2) ...
#8 10.79 Setting up manpages-dev (5.10-1) ...
#8 10.79 Setting up libxdmcp6:amd64 (1:1.1.2-3) ...
#8 10.80 Setting up libxcb1:amd64 (1.14-3) ...
#8 10.80 Setting up libgcc-10-dev:amd64 (10.2.1-6) ...
#8 10.80 Setting up libldap-2.4-2:amd64 (2.4.57+dfsg-3+deb11u1) ...
#8 10.80 Setting up libfreetype6:amd64 (2.10.4+dfsg-1+deb11u2) ...
#8 10.81 Setting up ucf (3.0043+deb11u2) ...
#8 10.87 debconf: unable to initialize frontend: Dialog
#8 10.87 debconf: (TERM is not set, so the dialog frontend is not usable.)
#8 10.87 debconf: falling back to frontend: Readline
#8 10.87 debconf: unable to initialize frontend: Readline
#8 10.87 debconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC contains: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.32.1 /usr/local/share/perl/5.32.1 /usr/lib/x86_64-linux-gnu/perl5/5.32 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl-base /usr/lib/x86_64-linux-gnu/perl/5.32 /usr/share/perl/5.32 /usr/local/lib/site_perl) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7.)
#8 10.87 debconf: falling back to frontend: Teletype
#8 10.89 Setting up cpp (4:10.2.1-1) ...
#8 10.90 Setting up libc6-dev:amd64 (2.31-13+deb11u13) ...
#8 10.90 Setting up libx11-6:amd64 (2:1.7.2-1+deb11u2) ...
#8 10.90 Setting up binutils-x86-64-linux-gnu (2.35.2-2) ...
#8 10.91 Setting up libxpm4:amd64 (1:3.5.12-1.1+deb11u1) ...
#8 10.91 Setting up fontconfig-config (2.13.1-4.2) ...
#8 10.97 debconf: unable to initialize frontend: Dialog
#8 10.97 debconf: (TERM is not set, so the dialog frontend is not usable.)
#8 10.97 debconf: falling back to frontend: Readline
#8 10.97 debconf: unable to initialize frontend: Readline
#8 10.97 debconf: (Can't locate Term/ReadLine.pm in @INC (you may need to install the Term::ReadLine module) (@INC contains: /etc/perl /usr/local/lib/x86_64-linux-gnu/perl/5.32.1 /usr/local/share/perl/5.32.1 /usr/lib/x86_64-linux-gnu/perl5/5.32 /usr/share/perl5 /usr/lib/x86_64-linux-gnu/perl-base /usr/lib/x86_64-linux-gnu/perl/5.32 /usr/share/perl/5.32 /usr/local/lib/site_perl) at /usr/share/perl5/Debconf/FrontEnd/Readline.pm line 7.)
#8 10.97 debconf: falling back to frontend: Teletype
#8 11.10 Setting up libpq5:amd64 (13.22-0+deb11u1) ...
#8 11.10 Setting up libpq-dev (13.22-0+deb11u1) ...
#8 11.11 Setting up binutils (2.35.2-2) ...
#8 11.11 Setting up gcc-10 (10.2.1-6) ...
#8 11.11 Setting up libfontconfig1:amd64 (2.13.1-4.2) ...
#8 11.11 Setting up gcc (4:10.2.1-1) ...
#8 11.12 Setting up libgd3:amd64 (2.3.0-2) ...
#8 11.13 Setting up libc-devtools (2.31-13+deb11u13) ...
#8 11.13 Processing triggers for libc-bin (2.31-13+deb11u13) ...
#8 DONE 11.3s

#9 [backend 4/7] COPY requirements.txt .
#9 DONE 0.0s

#10 [backend 5/7] RUN pip install --no-cache-dir -r requirements.txt
#10 1.658 WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1147)'))': /simple/flask/
#10 2.169 WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1147)'))': /simple/flask/
#10 3.180 WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1147)'))': /simple/flask/
#10 5.190 WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1147)'))': /simple/flask/
#10 9.203 WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1147)'))': /simple/flask/
#10 9.213 Could not fetch URL https://pypi.org/simple/flask/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/flask/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1147)'))) - skipping
#10 9.224 ERROR: Could not find a version that satisfies the requirement Flask==3.1.1 (from versions: none)
#10 9.224 ERROR: No matching distribution found for Flask==3.1.1
#10 9.234 Could not fetch URL https://pypi.org/simple/pip/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pip/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1147)'))) - skipping
#10 ERROR: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
------
 > [backend 5/7] RUN pip install --no-cache-dir -r requirements.txt:
1.658 WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1147)'))': /simple/flask/
2.169 WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1147)'))': /simple/flask/
3.180 WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1147)'))': /simple/flask/
5.190 WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1147)'))': /simple/flask/
9.203 WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1147)'))': /simple/flask/
9.213 Could not fetch URL https://pypi.org/simple/flask/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/flask/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1147)'))) - skipping
9.224 ERROR: Could not find a version that satisfies the requirement Flask==3.1.1 (from versions: none)
9.224 ERROR: No matching distribution found for Flask==3.1.1
9.234 Could not fetch URL https://pypi.org/simple/pip/: There was a problem confirming the ssl certificate: HTTPSConnectionPool(host='pypi.org', port=443): Max retries exceeded with url: /simple/pip/ (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self signed certificate in certificate chain (_ssl.c:1147)'))) - skipping
------
failed to solve: process "/bin/sh -c pip install --no-cache-dir -r requirements.txt" did not complete successfully: exit code: 1
All checks passed!
[main]	INFO	profile include tests: None
[main]	INFO	profile exclude tests: None
[main]	INFO	cli include tests: None
[main]	INFO	cli exclude tests: B101,B311,B105,B107,B108,B104,B110
Working... â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 100% 0:00:01
[json]	INFO	JSON output written to file: bandit_report.json

> thermacore-monitor-new@0.0.0 test /home/runner/work/ThermaCoreApp/ThermaCoreApp
> vitest


[1m[46m RUN [49m[22m [36mv3.2.4 [39m[90m/home/runner/work/ThermaCoreApp/ThermaCoreApp[39m

 [32mâœ“[39m src/tests/deviceStatusService.test.js [2m([22m[2m16 tests[22m[2m)[22m[32m 17[2mms[22m[39m
 [32mâœ“[39m src/tests/apiFetch.test.js [2m([22m[2m15 tests[22m[2m)[22m[32m 93[2mms[22m[39m
 [32mâœ“[39m src/tests/mockDataTimestamps.test.js [2m([22m[2m4 tests[22m[2m)[22m[32m 9[2mms[22m[39m
 [32mâœ“[39m src/tests/RemoteControl.test.jsx [2m([22m[2m8 tests[22m[2m)[22m[33m 533[2mms[22m[39m
 [31mâ¯[39m src/tests/workflow.test.js [2m([22m[2m6 tests[22m[2m | [22m[31m1 failed[39m[2m)[22m[32m 60[2mms[22m[39m
   [32mâœ“[39m Workflow Configuration[2m > [22mshould have a valid workflow file[32m 3[2mms[22m[39m
   [32mâœ“[39m Workflow Configuration[2m > [22mshould have workflow content[32m 1[2mms[22m[39m
[31m   [31mÃ—[31m Workflow Configuration[2m > [22mshould have frontend test step in workflow[39m[32m 53[2mms[22m[39m
[31m     â†’ expected 'name: Focused Code Quality and Securiâ€¦' to contain 'Run Frontend Tests'[39m
   [32mâœ“[39m Project Structure[2m > [22mshould have package.json[32m 0[2mms[22m[39m
   [32mâœ“[39m Project Structure[2m > [22mshould have test script configured[32m 1[2mms[22m[39m
   [32mâœ“[39m Project Structure[2m > [22mshould have vite config[32m 0[2mms[22m[39m
 [32mâœ“[39m src/tests/audioPlayer.test.js [2m([22m[2m3 tests[22m[2m)[22m[32m 7[2mms[22m[39m
 [32mâœ“[39m src/tests/ProtectedRoute.test.jsx [2m([22m[2m1 test[22m[2m)[22m[32m 76[2mms[22m[39m
[90mstderr[2m | src/tests/App.test.jsx[2m > [22m[2mApp[2m > [22m[2mrenders Login page for unauthenticated user
[22m[39mAn update to UnitProvider inside a test was not wrapped in act(...).

When testing, code that causes React state updates should be wrapped into act(...):

act(() => {
  /* fire events that update state */
});
/* assert on the output */

This ensures that you're testing the behavior the user would see in the browser. Learn more at https://react.dev/link/wrap-tests-with-act
An update to UnitProvider inside a test was not wrapped in act(...).

When testing, code that causes React state updates should be wrapped into act(...):

act(() => {
  /* fire events that update state */
});
/* assert on the output */

This ensures that you're testing the behavior the user would see in the browser. Learn more at https://react.dev/link/wrap-tests-with-act
An update to UnitProvider inside a test was not wrapped in act(...).

When testing, code that causes React state updates should be wrapped into act(...):

act(() => {
  /* fire events that update state */
});
/* assert on the output */

This ensures that you're testing the behavior the user would see in the browser. Learn more at https://react.dev/link/wrap-tests-with-act

 [32mâœ“[39m src/tests/Spinner.test.jsx [2m([22m[2m2 tests[22m[2m)[22m[32m 44[2mms[22m[39m
 [32mâœ“[39m src/tests/App.test.jsx [2m([22m[2m1 test[22m[2m)[22m[32m 93[2mms[22m[39m

[31mâŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯[39m[1m[41m Failed Tests 1 [49m[22m[31mâŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯[39m

[41m[1m FAIL [22m[49m src/tests/workflow.test.js[2m > [22mWorkflow Configuration[2m > [22mshould have frontend test step in workflow
[31m[1mAssertionError[22m: expected 'name: Focused Code Quality and Securiâ€¦' to contain 'Run Frontend Tests'[39m

[32m- Expected[39m
[31m+ Received[39m

[32m- Run Frontend Tests[39m
[31m+ name: Focused Code Quality and Security Checks[39m
[31m+ permissions:[39m
[31m+   contents: write[39m
[31m+   pull-requests: write[39m
[31m+   security-events: write[39m
[31m+[39m
[31m+ on:[39m
[31m+   push:[39m
[31m+     branches:[39m
[31m+       - main[39m
[31m+   pull_request:[39m
[31m+     branches:[39m
[31m+       - main[39m
[31m+[39m
[31m+ env:[39m
[31m+   SECRET_KEY: dummy-test-secret-key-123-for-github-actions[39m
[31m+   JWT_SECRET_KEY: dummy-jwt-secret-key-456-for-github-actions[39m
[31m+   FLASK_ENV: test[39m
[31m+   FLASK_APP: app.py[39m
[31m+   DATABASE_URL: postgresql://thermacore_user:thermacore_pass@db:5432/thermacore[39m
[31m+   # MQTT environment variables to prevent production config errors[39m
[31m+   MQTT_CERT_PATH: /dummy/path/to/cert.pem[39m
[31m+   MQTT_KEY_PATH: /dummy/path/to/key.pem[39m
[31m+   MQTT_CA_PATH: /dummy/path/to/ca.pem[39m
[31m+[39m
[31m+ jobs:[39m
[31m+   build-and-test:[39m
[31m+     runs-on: ubuntu-latest[39m
[31m+     timeout-minutes: 10[39m
[31m+     [39m
[31m+     steps:[39m
[31m+       - name: Checkout code[39m
[31m+         uses: actions/checkout@v4[39m
[31m+[39m
[31m+       - name: Set up Docker Buildx[39m
[31m+         uses: docker/setup-buildx-action@v3[39m
[31m+[39m
[31m+       - name: Set up Docker Compose[39m
[31m+         run: |[39m
[31m+           sudo systemctl start docker[39m
[31m+           docker --version[39m
[31m+           sudo curl -L "https://github.com/docker/compose/releases/download/v2.24.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose[39m
[31m+           sudo chmod +x /usr/local/bin/docker-compose[39m
[31m+           docker-compose --version[39m
[31m+[39m
[31m+       - name: Check Docker Compose Configuration and Services[39m
[31m+         run: |[39m
[31m+           echo "ðŸ“‹ Checking docker-compose.yml file..."[39m
[31m+           ls -la docker-compose.yml || echo "âŒ docker-compose.yml not found"[39m
[31m+           echo "ðŸ“‹ Available services:"[39m
[31m+           docker-compose config --services || echo "âŒ Cannot parse docker-compose.yml"[39m
[31m+           [39m
[31m+           echo "ðŸ” Checking for database service names..."[39m
[31m+           SERVICES=$(docker-compose config --services)[39m
[31m+           echo "Available services: $SERVICES"[39m
[31m+           [39m
[31m+           if echo "$SERVICES" | grep -q "timescaledb"; then[39m
[31m+             echo "âœ… Found 'timescaledb' service"[39m
[31m+             DB_SERVICE="timescaledb"[39m
[31m+           elif echo "$SERVICES" | grep -q "db"; then[39m
[31m+             echo "âœ… Found 'db' service" [39m
[31m+             DB_SERVICE="db"[39m
[31m+           elif echo "$SERVICES" | grep -q "postgres"; then[39m
[31m+             echo "âœ… Found 'postgres' service"[39m
[31m+             DB_SERVICE="postgres"[39m
[31m+           elif echo "$SERVICES" | grep -q "database"; then[39m
[31m+             echo "âœ… Found 'database' service"[39m
[31m+             DB_SERVICE="database"[39m
[31m+           else[39m
[31m+             echo "âŒ No database service found. Available: $SERVICES"[39m
[31m+             exit 1[39m
[31m+           fi[39m
[31m+           [39m
[31m+           echo "ðŸ“Š Using database service: $DB_SERVICE"[39m
[31m+[39m
[31m+       - name: Fix Locust Version in Requirements[39m
[31m+         run: |[39m
[31m+           cd backend[39m
[31m+           if grep -q "locust==2.35.0" requirements.txt; then[39m
[31m+             echo "ðŸ”§ Fixing locust version from 2.35.0 to 2.20.1"[39m
[31m+             sed -i 's/locust==2.35.0/locust==2.20.1/' requirements.txt[39m
[31m+             echo "âœ… Updated requirements.txt"[39m
[31m+             cat requirements.txt | grep locust[39m
[31m+           fi[39m
[31m+[39m
[31m+       - name: Create Temporary Docker Compose Without Frontend[39m
[31m+         run: |[39m
[31m+           echo "ðŸ”§ Creating temporary docker-compose.ci.yml without frontend..."[39m
[31m+           # Create a temporary compose file that excludes the frontend service[39m
[31m+           docker-compose config > docker-compose.ci.yml[39m
[31m+           [39m
[31m+           # Remove frontend service from the config[39m
[31m+           python3 -c "[39m
[31m+           import yaml[39m
[31m+           with open('docker-compose.ci.yml', 'r') as f:[39m
[31m+               config = yaml.safe_load(f)[39m
[31m+           [39m
[31m+           # Remove frontend service if it exists[39m
[31m+           if 'services' in config and 'frontend' in config['services']:[39m
[31m+               del config['services']['frontend'][39m
[31m+               print('âœ… Removed frontend service from docker-compose.ci.yml')[39m
[31m+           else:[39m
[31m+               print('â„¹ï¸  No frontend service found in docker-compose.yml')[39m
[31m+           [39m
[31m+           # Write the modified config[39m
[31m+           with open('docker-compose.ci.yml', 'w') as f:[39m
[31m+               yaml.dump(config, f)[39m
[31m+           "[39m
[31m+           [39m
[31m+           echo "ðŸ“‹ Temporary docker-compose.ci.yml created:"[39m
[31m+           cat docker-compose.ci.yml | head -20[39m
[31m+[39m
[31m+       - name: Build Database and Backend Only (Using CI Compose)[39m
[31m+         run: |[39m
[31m+           echo "ðŸ—ï¸ Building database and backend services using CI compose file..."[39m
[31m+           [39m
[31m+           # Build database first to ensure it's ready[39m
[31m+           docker-compose -f docker-compose.ci.yml build $DB_SERVICE[39m
[31m+           echo "âœ… Database service built"[39m
[31m+           [39m
[31m+           # Then build backend only[39m
[31m+           docker-compose -f docker-compose.ci.yml build backend[39m
[31m+           echo "âœ… Backend built successfully"[39m
[31m+[39m
[31m+       - name: Start Database with Simplified Health Check[39m
[31m+         run: |[39m
[31m+           # Determine database service name[39m
[31m+           SERVICES=$(docker-compose -f docker-compose.ci.yml config --services)[39m
[31m+           if echo "$SERVICES" | grep -q "timescaledb"; then[39m
[31m+             DB_SERVICE="timescaledb"[39m
[31m+           elif echo "$SERVICES" | grep -q "db"; then[39m
[31m+             DB_SERVICE="db"[39m
[31m+           elif echo "$SERVICES" | grep -q "postgres"; then[39m
[31m+             DB_SERVICE="postgres"[39m
[31m+           elif echo "$SERVICES" | grep -q "database"; then[39m
[31m+             DB_SERVICE="database"[39m
[31m+           else[39m
[31m+             echo "âŒ Cannot determine database service"[39m
[31m+             exit 1[39m
[31m+           fi[39m
[31m+           [39m
[31m+           echo "ðŸš€ Starting database service: $DB_SERVICE"[39m
[31m+           docker-compose -f docker-compose.ci.yml up -d $DB_SERVICE[39m
[31m+           [39m
[31m+           echo "â³ Waiting for database to start (simple wait)..."[39m
[31m+           # Simple sleep to allow database to initialize[39m
[31m+           sleep 30[39m
[31m+           [39m
[31m+           echo "ðŸ”§ Testing database connection..."[39m
[31m+           # Try multiple connection attempts with simpler method[39m
[31m+           for i in {1..10}; do[39m
[31m+             if docker-compose -f docker-compose.ci.yml exec -T $DB_SERVICE psql -U postgres -c "SELECT version();" 2>/dev/null; then[39m
[31m+               echo "âœ… Database is ready and responding"[39m
[31m+               break[39m
[31m+             else[39m
[31m+               echo "â³ Database not ready yet, attempt $i/10..."[39m
[31m+               sleep 10[39m
[31m+             fi[39m
[31m+           done[39m
[31m+           [39m
[31m+           # Final connection test[39m
[31m+           if docker-compose -f docker-compose.ci.yml exec -T $DB_SERVICE psql -U postgres -c "SELECT 1;" 2>/dev/null; then[39m
[31m+             echo "ðŸŽ‰ Database connection successful!"[39m
[31m+           else[39m
[31m+             echo "âŒ Database failed to start properly"[39m
[31m+             echo "ðŸ“‹ Checking database logs:"[39m
[31m+             docker-compose -f docker-compose.ci.yml logs $DB_SERVICE[39m
[31m+             exit 1[39m
[31m+           fi[39m
[31m+[39m
[31m+       - name: Initialize Test Database (Fixed Transaction Issue)[39m
[31m+         run: |[39m
[31m+           SERVICES=$(docker-compose -f docker-compose.ci.yml config --services)[39m
[31m+           if echo "$SERVICES" | grep -q "timescaledb"; then[39m
[31m+             DB_SERVICE="timescaledb"[39m
[31m+           elif echo "$SERVICES" | grep -q "db"; then[39m
[31m+             DB_SERVICE="db"[39m
[31m+           elif echo "$SERVICES" | grep -q "postgres"; then[39m
[31m+             DB_SERVICE="postgres"[39m
[31m+           elif echo "$SERVICES" | grep -q "database"; then[39m
[31m+             DB_SERVICE="database"[39m
[31m+           else[39m
[31m+             echo "âŒ Cannot determine database service"[39m
[31m+             exit 1[39m
[31m+           fi[39m
[31m+           [39m
[31m+           echo "ðŸ”§ Initializing test database on service: $DB_SERVICE"[39m
[31m+           # Use single commands to avoid transaction blocks[39m
[31m+           docker-compose -f docker-compose.ci.yml exec -T $DB_SERVICE psql -U postgres -c "DROP DATABASE IF EXISTS thermacore;" || echo "âš ï¸ Could not drop database (might not exist)"[39m
[31m+           docker-compose -f docker-compose.ci.yml exec -T $DB_SERVICE psql -U postgres -c "DROP USER IF EXISTS thermacore_user;" || echo "âš ï¸ Could not drop user (might not exist)"[39m
[31m+           docker-compose -f docker-compose.ci.yml exec -T $DB_SERVICE psql -U postgres -c "CREATE USER thermacore_user WITH PASSWORD 'thermacore_pass';" || echo "âš ï¸ User might already exist"[39m
[31m+           docker-compose -f docker-compose.ci.yml exec -T $DB_SERVICE psql -U postgres -c "CREATE DATABASE thermacore OWNER thermacore_user;" || echo "âš ï¸ Database might already exist"[39m
[31m+           docker-compose -f docker-compose.ci.yml exec -T $DB_SERVICE psql -U postgres -c "GRANT ALL PRIVILEGES ON DATABASE thermacore TO thermacore_user;" || echo "âš ï¸ Grant might already exist"[39m
[31m+           [39m
[31m+           echo "âœ… Database setup completed"[39m
[31m+[39m
[31m+       - name: Run Backend Tests[39m
[31m+         run: |[39m
[31m+           echo "ðŸ§ª Running backend tests..."[39m
[31m+           # Tests use conftest.py for database initialization[39m
[31m+           # conftest.py creates a temporary database and initializes it with all models[39m
[31m+           docker-compose -f docker-compose.ci.yml run --rm backend python -m pytest -v --tb=short[39m
[31m+[39m
[31m+       - name: Stop Services[39m
[31m+         if: always()[39m
[31m+         run: |[39m
[31m+           docker-compose -f docker-compose.ci.yml down --remove-orphans --timeout 30 || echo "Docker compose down failed but continuing..."[39m
[31m+[39m
[31m+       - name: Cleanup Temporary Files[39m
[31m+         if: always()[39m
[31m+         run: |[39m
[31m+           rm -f docker-compose.ci.yml || echo "No temporary file to clean up"[39m
[31m+[39m
[31m+   python-quality-and-security:[39m
[31m+     runs-on: ubuntu-latest[39m
[31m+     steps:[39m
[31m+       - name: Checkout code[39m
[31m+         uses: actions/checkout@v4[39m
[31m+[39m
[31m+       - name: Set up Python[39m
[31m+         uses: actions/setup-python@v5[39m
[31m+         with:[39m
[31m+           python-version: '3.10'[39m
[31m+[39m
[31m+       - name: Fix Locust Version for Quality Checks[39m
[31m+         run: |[39m
[31m+           cd backend[39m
[31m+           if grep -q "locust==2.35.0" requirements.txt; then[39m
[31m+             sed -i 's/locust==2.35.0/locust==2.20.1/' requirements.txt[39m
[31m+           fi[39m
[31m+[39m
[31m+       - name: Install Python dependencies[39m
[31m+         run: pip install -r backend/requirements.txt ruff bandit[39m
[31m+[39m
[31m+       - name: Run Ruff[39m
[31m+         run: ruff check .[39m
[31m+         working-directory: backend[39m
[31m+[39m
[31m+       - name: Run Bandit and Generate SARIF Report[39m
[31m+         run: |[39m
[31m+           # Run Bandit excluding test files and directories[39m
[31m+           # --exclude: excludes test directories and test files from scan[39m
[31m+           # --skip B101: skips assert_used check (pytest tests use bare asserts)[39m
[31m+           # --skip others: skip other low-risk checks[39m
[31m+           bandit -r . -f json -o bandit_report.json \[39m
[31m+             --exclude '**/tests/**,**/test_*.py,**/validate_*.py' \[39m
[31m+             --skip B101,B311,B105,B107,B108,B104,B110 || true[39m
[31m+           [39m
[31m+           # Generate clean SARIF output using heredoc to avoid shell quoting issues[39m
[31m+           python - <<'EOF'[39m
[31m+           import json[39m
[31m+           import sys[39m
[31m+           [39m
[31m+           def create_minimal_sarif():[39m
[31m+               """Create a minimal valid SARIF structure."""[39m
[31m+               return {[39m
[31m+                   "$schema": "https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json",[39m
[31m+                   "version": "2.1.0",[39m
[31m+                   "runs": [{[39m
[31m+                       "tool": {[39m
[31m+                           "driver": {[39m
[31m+                               "name": "Bandit",[39m
[31m+                               "version": "1.7.0"[39m
[31m+                           }[39m
[31m+                       },[39m
[31m+                       "results": [][39m
[31m+                   }][39m
[31m+               }[39m
[31m+           [39m
[31m+           try:[39m
[31m+               # Read Bandit JSON report[39m
[31m+               with open('bandit_report.json', 'r') as f:[39m
[31m+                   bandit_data = json.load(f)[39m
[31m+               [39m
[31m+               # Validate that we have the expected structure[39m
[31m+               if not isinstance(bandit_data, dict):[39m
[31m+                   print(f"âš ï¸  bandit_report.json is not a dict, creating minimal SARIF")[39m
[31m+                   sarif = create_minimal_sarif()[39m
[31m+               else:[39m
[31m+                   # Create valid SARIF 2.1.0 format - only standard properties[39m
[31m+                   sarif = create_minimal_sarif()[39m
[31m+                   [39m
[31m+                   # Process Bandit results - only HIGH and MEDIUM severity[39m
[31m+                   results = bandit_data.get('results', [])[39m
[31m+                   if not isinstance(results, list):[39m
[31m+                       print(f"âš ï¸  'results' is not a list in bandit_report.json")[39m
[31m+                       results = [][39m
[31m+                   [39m
[31m+                   for issue in results:[39m
[31m+                       if not isinstance(issue, dict):[39m
[31m+                           continue[39m
[31m+                       [39m
[31m+                       severity = issue.get('issue_severity', '')[39m
[31m+                       if severity in ['HIGH', 'MEDIUM']:[39m
[31m+                           sarif['runs'][0]['results'].append({[39m
[31m+                               'ruleId': issue.get('test_id', 'unknown'),[39m
[31m+                               'level': 'error' if severity == 'HIGH' else 'warning',[39m
[31m+                               'message': {[39m
[31m+                                   'text': issue.get('issue_text', 'No description provided')[39m
[31m+                               },[39m
[31m+                               'locations': [{[39m
[31m+                                   'physicalLocation': {[39m
[31m+                                       'artifactLocation': {[39m
[31m+                                           'uri': issue.get('filename', 'unknown').replace('./', '')[39m
[31m+                                       },[39m
[31m+                                       'region': {[39m
[31m+                                           'startLine': issue.get('line_number', 1),[39m
[31m+                                           'startColumn': issue.get('col_offset', 1)[39m
[31m+                                       }[39m
[31m+                                   }[39m
[31m+                               }][39m
[31m+                           })[39m
[31m+                   [39m
[31m+                   print(f"ðŸ“Š Generated SARIF with {len(sarif['runs'][0]['results'])} high/medium severity issues")[39m
[31m+               [39m
[31m+               # Write clean SARIF - no 'errors' or 'generated_at' properties[39m
[31m+               with open('bandit_sarif.json', 'w') as f:[39m
[31m+                   json.dump(sarif, f, indent=2)[39m
[31m+               [39m
[31m+               print("âœ… SARIF file written successfully")[39m
[31m+               [39m
[31m+           except FileNotFoundError:[39m
[31m+               print("âš ï¸  bandit_report.json not found, creating minimal SARIF")[39m
[31m+               sarif = create_minimal_sarif()[39m
[31m+               with open('bandit_sarif.json', 'w') as f:[39m
[31m+                   json.dump(sarif, f, indent=2)[39m
[31m+           except json.JSONDecodeError as e:[39m
[31m+               print(f"âŒ Failed to parse bandit_report.json: {e}")[39m
[31m+               print("Creating minimal valid SARIF")[39m
[31m+               sarif = create_minimal_sarif()[39m
[31m+               with open('bandit_sarif.json', 'w') as f:[39m
[31m+                   json.dump(sarif, f, indent=2)[39m
[31m+           except Exception as e:[39m
[31m+               print(f"âŒ Unexpected error: {e}")[39m
[31m+               sarif = create_minimal_sarif()[39m
[31m+               with open('bandit_sarif.json', 'w') as f:[39m
[31m+                   json.dump(sarif, f, indent=2)[39m
[31m+           EOF[39m
[31m+           [39m
[31m+           # Validate generated SARIF[39m
[31m+           echo "ðŸ” Validating generated SARIF file:"[39m
[31m+           head -20 bandit_sarif.json[39m
[31m+           [39m
[31m+           # Verify required properties exist[39m
[31m+           python - <<'EOF'[39m
[31m+           import json[39m
[31m+           try:[39m
[31m+               with open('bandit_sarif.json', 'r') as f:[39m
[31m+                   sarif = json.load(f)[39m
[31m+               [39m
[31m+               # Check required SARIF properties[39m
[31m+               assert '$schema' in sarif, "Missing $schema property"[39m
[31m+               assert 'version' in sarif, "Missing version property"[39m
[31m+               assert 'runs' in sarif, "Missing runs property"[39m
[31m+               assert isinstance(sarif['runs'], list), "runs must be a list"[39m
[31m+               assert len(sarif['runs']) > 0, "runs must not be empty"[39m
[31m+               [39m
[31m+               # Check no extra top-level properties[39m
[31m+               allowed_keys = {'$schema', 'version', 'runs'}[39m
[31m+               extra_keys = set(sarif.keys()) - allowed_keys[39m
[31m+               if extra_keys:[39m
[31m+                   print(f"âš ï¸  Found unexpected top-level keys: {extra_keys}")[39m
[31m+                   sys.exit(1)[39m
[31m+               [39m
[31m+               print("âœ… SARIF validation passed")[39m
[31m+           except Exception as e:[39m
[31m+               print(f"âŒ SARIF validation failed: {e}")[39m
[31m+               import sys[39m
[31m+               sys.exit(1)[39m
[31m+           EOF[39m
[31m+         working-directory: backend[39m
[31m+[39m
[31m+       - name: Upload Security Scan Results[39m
[31m+         uses: github/codeql-action/upload-sarif@v3[39m
[31m+         if: always()[39m
[31m+         with:[39m
[31m+           sarif_file: backend/bandit_sarif.json[39m
[31m+[39m
[31m+       - name: Upload Bandit Report Artifact[39m
[31m+         uses: actions/upload-artifact@v4[39m
[31m+         if: always()[39m
[31m+         with:[39m
[31m+           name: bandit-security-report[39m
[31m+           path: backend/bandit_report.json[39m
[31m+[39m
[31m+   dependency-and-secret-scanning:[39m
[31m+     runs-on: ubuntu-latest[39m
[31m+     steps:[39m
[31m+       - name: Checkout code[39m
[31m+         uses: actions/checkout@v4[39m
[31m+[39m
[31m+       - name: Install and Run Gitleaks Properly[39m
[31m+         run: |[39m
[31m+           # Install gitleaks with proper configuration[39m
[31m+           curl -sSfL https://github.com/gitleaks/gitleaks/releases/download/v8.18.1/gitleaks_8.18.1_linux_x64.tar.gz | tar xz -C /tmp/[39m
[31m+           chmod +x /tmp/gitleaks[39m
[31m+           sudo mv /tmp/gitleaks /usr/local/bin/[39m
[31m+           [39m
[31m+           echo "ðŸ” Creating gitleaks configuration..."[39m
[31m+           # Create a proper config file that excludes test files and documentation[39m
[31m+           cat > .gitleaks.toml << 'EOF'[39m
[31m+           title = "ThermaCoreApp Gitleaks Config"[39m
[31m+           [allowlist][39m
[31m+             description = "Allow test files and documentation"[39m
[31m+             files = [[39m
[31m+               '''.*\.md$''',[39m
[31m+               '''.*\.txt$''',[39m
[31m+               '''.*test.*\.py$''',[39m
[31m+               '''.*Test.*\.py$''',[39m
[31m+               '''.*spec.*\.py$''',[39m
[31m+               '''.*fixture.*\.py$''',[39m
[31m+               '''conftest\.py$''',[39m
[31m+               '''.*__init__\.py$''',[39m
[31m+               '''.*\.lock$''',[39m
[31m+               '''.*\.json$''',[39m
[31m+               '''.*\.yml$''',[39m
[31m+               '''.*\.yaml$''',[39m
[31m+               '''\.env\.example$''',[39m
[31m+               '''\.gitignore$''',[39m
[31m+               '''bandit_report\.json$''',[39m
[31m+               '''coverage\.xml$''',[39m
[31m+               '''.*\.html$''',[39m
[31m+               '''.*\.sql$''',[39m
[31m+               '''.*\.log$''',[39m
[31m+               '''\.github/workflows/.*''',[39m
[31m+               '''backend/app/tests/.*''',[39m
[31m+               '''backend/app/utils/validate_secure_logging\.py$''',[39m
[31m+               '''backend/SECURITY_.*''',[39m
[31m+               '''backend/SECRET_.*''',[39m
[31m+               '''backend/SECURE_.*''',[39m
[31m+               '''frontend/src/__tests__/.*''',[39m
[31m+             ][39m
[31m+           EOF[39m
[31m+           [39m
[31m+           echo "ðŸ” Running gitleaks secret scan with proper config..."[39m
[31m+           gitleaks detect --source . --config .gitleaks.toml --no-git --verbose --redact[39m
[31m+           [39m
[31m+           echo "âœ… Gitleaks scan completed successfully"[39m
[31m+[39m
[31m+       - name: Dependency Review[39m
[31m+         if: github.event_name == 'pull_request'[39m
[31m+         uses: actions/dependency-review-action@v4[39m
[31m+[39m
[31m+       - name: Run OSV Scanner with Go Install (Most Reliable)[39m
[31m+         run: |[39m
[31m+           echo "ðŸ”§ Installing OSV Scanner via Go install..."[39m
[31m+           # Install Go if not present[39m
[31m+           if ! command -v go &> /dev/null; then[39m
[31m+             curl -L https://golang.org/dl/go1.21.0.linux-amd64.tar.gz | sudo tar -C /usr/local -xzf -[39m
[31m+             echo 'export PATH=$PATH:/usr/local/go/bin' >> ~/.bashrc[39m
[31m+             source ~/.bashrc[39m
[31m+           fi[39m
[31m+           [39m
[31m+           # Install OSV Scanner via Go[39m
[31m+           go install github.com/google/osv-scanner/cmd/osv-scanner@v1[39m
[31m+           [39m
[31m+           echo "ðŸ” Running OSV Scanner..."[39m
[31m+           ~/go/bin/osv-scanner -r . --skip-git || echo "OSV Scanner completed with findings"[39m
[31m+[39m
[31m+   dependabot-auto-merge:[39m
[31m+     runs-on: ubuntu-latest[39m
[31m+     if: ${{ github.actor == 'dependabot[bot]' }}[39m
[31m+     permissions:[39m
[31m+       contents: write[39m
[31m+       pull-requests: write[39m
[31m+     steps:[39m
[31m+       - name: Dependabot metadata[39m
[31m+         id: metadata[39m
[31m+         uses: dependabot/fetch-metadata@v2[39m
[31m+         with:[39m
[31m+           github-token: "${{ secrets.GITHUB_TOKEN }}"[39m
[31m+[39m
[31m+       - name: Enable auto-merge for Dependabot PRs[39m
[31m+         if: ${{ steps.metadata.outputs.update-type == 'version-update:semver-patch' }}[39m
[31m+         run: |[39m
[31m+           gh pr merge --auto --merge "${{ github.event.pull_request.html_url }}"[39m
[31m+         env:[39m
[31m+           GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}[39m
[31m+[39m
[31m+       - name: Approve Dependabot PRs[39m
[31m+         if: ${{ steps.metadata.outputs.update-type == 'version-update:semver-patch' }}[39m
[31m+         run: |[39m
[31m+           gh pr review --approve "${{ github.event.pull_request.html_url }}"[39m
[31m+         env:[39m
[31m+           GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}[39m
[31m+[39m

[36m [2mâ¯[22m src/tests/workflow.test.js:[2m27:29[22m[39m
    [90m 25| [39m    
    [90m 26| [39m    [34mexpect[39m(workflowContent)[33m.[39m[34mtoContain[39m([32m'build-and-test:'[39m)[33m;[39m
    [90m 27| [39m    [34mexpect[39m(workflowContent)[33m.[39m[34mtoContain[39m([32m'Run Frontend Tests'[39m)[33m;[39m
    [90m   | [39m                            [31m^[39m
    [90m 28| [39m  })[33m;[39m
    [90m 29| [39m})[33m;[39m

[31m[2mâŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯âŽ¯[1/1]âŽ¯[22m[39m


[2m Test Files [22m [1m[31m1 failed[39m[22m[2m | [22m[1m[32m8 passed[39m[22m[90m (9)[39m
[2m      Tests [22m [1m[31m1 failed[39m[22m[2m | [22m[1m[32m55 passed[39m[22m[90m (56)[39m
[2m   Start at [22m 09:52:19
[2m   Duration [22m 4.17s[2m (transform 1.04s, setup 674ms, collect 2.70s, tests 932ms, environment 5.15s, prepare 874ms)[22m


::error file=/home/runner/work/ThermaCoreApp/ThermaCoreApp/src/tests/workflow.test.js,title=src/tests/workflow.test.js > Workflow Configuration > should have frontend test step in workflow,line=27,column=29::AssertionError: expected 'name: Focused Code Quality and Securiâ€¦' to contain 'Run Frontend Tests'%0A%0A- Expected%0A+ Received%0A%0A- Run Frontend Tests%0A+ name: Focused Code Quality and Security Checks%0A+ permissions:%0A+   contents: write%0A+   pull-requests: write%0A+   security-events: write%0A+%0A+ on:%0A+   push:%0A+     branches:%0A+       - main%0A+   pull_request:%0A+     branches:%0A+       - main%0A+%0A+ env:%0A+   SECRET_KEY: dummy-test-secret-key-123-for-github-actions%0A+   JWT_SECRET_KEY: dummy-jwt-secret-key-456-for-github-actions%0A+   FLASK_ENV: test%0A+   FLASK_APP: app.py%0A+   DATABASE_URL: postgresql://thermacore_user:thermacore_pass@db:5432/thermacore%0A+   # MQTT environment variables to prevent production config errors%0A+   MQTT_CERT_PATH: /dummy/path/to/cert.pem%0A+   MQTT_KEY_PATH: /dummy/path/to/key.pem%0A+   MQTT_CA_PATH: /dummy/path/to/ca.pem%0A+%0A+ jobs:%0A+   build-and-test:%0A+     runs-on: ubuntu-latest%0A+     timeout-minutes: 10%0A+     %0A+     steps:%0A+       - name: Checkout code%0A+         uses: actions/checkout@v4%0A+%0A+       - name: Set up Docker Buildx%0A+         uses: docker/setup-buildx-action@v3%0A+%0A+       - name: Set up Docker Compose%0A+         run: |%0A+           sudo systemctl start docker%0A+           docker --version%0A+           sudo curl -L "https://github.com/docker/compose/releases/download/v2.24.0/docker-compose-$(uname -s)-$(uname -m)" -o /usr/local/bin/docker-compose%0A+           sudo chmod +x /usr/local/bin/docker-compose%0A+           docker-compose --version%0A+%0A+       - name: Check Docker Compose Configuration and Services%0A+         run: |%0A+           echo "ðŸ“‹ Checking docker-compose.yml file..."%0A+           ls -la docker-compose.yml || echo "âŒ docker-compose.yml not found"%0A+           echo "ðŸ“‹ Available services:"%0A+           docker-compose config --services || echo "âŒ Cannot parse docker-compose.yml"%0A+           %0A+           echo "ðŸ” Checking for database service names..."%0A+           SERVICES=$(docker-compose config --services)%0A+           echo "Available services: $SERVICES"%0A+           %0A+           if echo "$SERVICES" | grep -q "timescaledb"; then%0A+             echo "âœ… Found 'timescaledb' service"%0A+             DB_SERVICE="timescaledb"%0A+           elif echo "$SERVICES" | grep -q "db"; then%0A+             echo "âœ… Found 'db' service" %0A+             DB_SERVICE="db"%0A+           elif echo "$SERVICES" | grep -q "postgres"; then%0A+             echo "âœ… Found 'postgres' service"%0A+             DB_SERVICE="postgres"%0A+           elif echo "$SERVICES" | grep -q "database"; then%0A+             echo "âœ… Found 'database' service"%0A+             DB_SERVICE="database"%0A+           else%0A+             echo "âŒ No database service found. Available: $SERVICES"%0A+             exit 1%0A+           fi%0A+           %0A+           echo "ðŸ“Š Using database service: $DB_SERVICE"%0A+%0A+       - name: Fix Locust Version in Requirements%0A+         run: |%0A+           cd backend%0A+           if grep -q "locust==2.35.0" requirements.txt; then%0A+             echo "ðŸ”§ Fixing locust version from 2.35.0 to 2.20.1"%0A+             sed -i 's/locust==2.35.0/locust==2.20.1/' requirements.txt%0A+             echo "âœ… Updated requirements.txt"%0A+             cat requirements.txt | grep locust%0A+           fi%0A+%0A+       - name: Create Temporary Docker Compose Without Frontend%0A+         run: |%0A+           echo "ðŸ”§ Creating temporary docker-compose.ci.yml without frontend..."%0A+           # Create a temporary compose file that excludes the frontend service%0A+           docker-compose config > docker-compose.ci.yml%0A+           %0A+           # Remove frontend service from the config%0A+           python3 -c "%0A+           import yaml%0A+           with open('docker-compose.ci.yml', 'r') as f:%0A+               config = yaml.safe_load(f)%0A+           %0A+           # Remove frontend service if it exists%0A+           if 'services' in config and 'frontend' in config['services']:%0A+               del config['services']['frontend']%0A+               print('âœ… Removed frontend service from docker-compose.ci.yml')%0A+           else:%0A+               print('â„¹ï¸  No frontend service found in docker-compose.yml')%0A+           %0A+           # Write the modified config%0A+           with open('docker-compose.ci.yml', 'w') as f:%0A+               yaml.dump(config, f)%0A+           "%0A+           %0A+           echo "ðŸ“‹ Temporary docker-compose.ci.yml created:"%0A+           cat docker-compose.ci.yml | head -20%0A+%0A+       - name: Build Database and Backend Only (Using CI Compose)%0A+         run: |%0A+           echo "ðŸ—ï¸ Building database and backend services using CI compose file..."%0A+           %0A+           # Build database first to ensure it's ready%0A+           docker-compose -f docker-compose.ci.yml build $DB_SERVICE%0A+           echo "âœ… Database service built"%0A+           %0A+           # Then build backend only%0A+           docker-compose -f docker-compose.ci.yml build backend%0A+           echo "âœ… Backend built successfully"%0A+%0A+       - name: Start Database with Simplified Health Check%0A+         run: |%0A+           # Determine database service name%0A+           SERVICES=$(docker-compose -f docker-compose.ci.yml config --services)%0A+           if echo "$SERVICES" | grep -q "timescaledb"; then%0A+             DB_SERVICE="timescaledb"%0A+           elif echo "$SERVICES" | grep -q "db"; then%0A+             DB_SERVICE="db"%0A+           elif echo "$SERVICES" | grep -q "postgres"; then%0A+             DB_SERVICE="postgres"%0A+           elif echo "$SERVICES" | grep -q "database"; then%0A+             DB_SERVICE="database"%0A+           else%0A+             echo "âŒ Cannot determine database service"%0A+             exit 1%0A+           fi%0A+           %0A+           echo "ðŸš€ Starting database service: $DB_SERVICE"%0A+           docker-compose -f docker-compose.ci.yml up -d $DB_SERVICE%0A+           %0A+           echo "â³ Waiting for database to start (simple wait)..."%0A+           # Simple sleep to allow database to initialize%0A+           sleep 30%0A+           %0A+           echo "ðŸ”§ Testing database connection..."%0A+           # Try multiple connection attempts with simpler method%0A+           for i in {1..10}; do%0A+             if docker-compose -f docker-compose.ci.yml exec -T $DB_SERVICE psql -U postgres -c "SELECT version();" 2>/dev/null; then%0A+               echo "âœ… Database is ready and responding"%0A+               break%0A+             else%0A+               echo "â³ Database not ready yet, attempt $i/10..."%0A+               sleep 10%0A+             fi%0A+           done%0A+           %0A+           # Final connection test%0A+           if docker-compose -f docker-compose.ci.yml exec -T $DB_SERVICE psql -U postgres -c "SELECT 1;" 2>/dev/null; then%0A+             echo "ðŸŽ‰ Database connection successful!"%0A+           else%0A+             echo "âŒ Database failed to start properly"%0A+             echo "ðŸ“‹ Checking database logs:"%0A+             docker-compose -f docker-compose.ci.yml logs $DB_SERVICE%0A+             exit 1%0A+           fi%0A+%0A+       - name: Initialize Test Database (Fixed Transaction Issue)%0A+         run: |%0A+           SERVICES=$(docker-compose -f docker-compose.ci.yml config --services)%0A+           if echo "$SERVICES" | grep -q "timescaledb"; then%0A+             DB_SERVICE="timescaledb"%0A+           elif echo "$SERVICES" | grep -q "db"; then%0A+             DB_SERVICE="db"%0A+           elif echo "$SERVICES" | grep -q "postgres"; then%0A+             DB_SERVICE="postgres"%0A+           elif echo "$SERVICES" | grep -q "database"; then%0A+             DB_SERVICE="database"%0A+           else%0A+             echo "âŒ Cannot determine database service"%0A+             exit 1%0A+           fi%0A+           %0A+           echo "ðŸ”§ Initializing test database on service: $DB_SERVICE"%0A+           # Use single commands to avoid transaction blocks%0A+           docker-compose -f docker-compose.ci.yml exec -T $DB_SERVICE psql -U postgres -c "DROP DATABASE IF EXISTS thermacore;" || echo "âš ï¸ Could not drop database (might not exist)"%0A+           docker-compose -f docker-compose.ci.yml exec -T $DB_SERVICE psql -U postgres -c "DROP USER IF EXISTS thermacore_user;" || echo "âš ï¸ Could not drop user (might not exist)"%0A+           docker-compose -f docker-compose.ci.yml exec -T $DB_SERVICE psql -U postgres -c "CREATE USER thermacore_user WITH PASSWORD 'thermacore_pass';" || echo "âš ï¸ User might already exist"%0A+           docker-compose -f docker-compose.ci.yml exec -T $DB_SERVICE psql -U postgres -c "CREATE DATABASE thermacore OWNER thermacore_user;" || echo "âš ï¸ Database might already exist"%0A+           docker-compose -f docker-compose.ci.yml exec -T $DB_SERVICE psql -U postgres -c "GRANT ALL PRIVILEGES ON DATABASE thermacore TO thermacore_user;" || echo "âš ï¸ Grant might already exist"%0A+           %0A+           echo "âœ… Database setup completed"%0A+%0A+       - name: Run Backend Tests%0A+         run: |%0A+           echo "ðŸ§ª Running backend tests..."%0A+           # Tests use conftest.py for database initialization%0A+           # conftest.py creates a temporary database and initializes it with all models%0A+           docker-compose -f docker-compose.ci.yml run --rm backend python -m pytest -v --tb=short%0A+%0A+       - name: Stop Services%0A+         if: always()%0A+         run: |%0A+           docker-compose -f docker-compose.ci.yml down --remove-orphans --timeout 30 || echo "Docker compose down failed but continuing..."%0A+%0A+       - name: Cleanup Temporary Files%0A+         if: always()%0A+         run: |%0A+           rm -f docker-compose.ci.yml || echo "No temporary file to clean up"%0A+%0A+   python-quality-and-security:%0A+     runs-on: ubuntu-latest%0A+     steps:%0A+       - name: Checkout code%0A+         uses: actions/checkout@v4%0A+%0A+       - name: Set up Python%0A+         uses: actions/setup-python@v5%0A+         with:%0A+           python-version: '3.10'%0A+%0A+       - name: Fix Locust Version for Quality Checks%0A+         run: |%0A+           cd backend%0A+           if grep -q "locust==2.35.0" requirements.txt; then%0A+             sed -i 's/locust==2.35.0/locust==2.20.1/' requirements.txt%0A+           fi%0A+%0A+       - name: Install Python dependencies%0A+         run: pip install -r backend/requirements.txt ruff bandit%0A+%0A+       - name: Run Ruff%0A+         run: ruff check .%0A+         working-directory: backend%0A+%0A+       - name: Run Bandit and Generate SARIF Report%0A+         run: |%0A+           # Run Bandit excluding test files and directories%0A+           # --exclude: excludes test directories and test files from scan%0A+           # --skip B101: skips assert_used check (pytest tests use bare asserts)%0A+           # --skip others: skip other low-risk checks%0A+           bandit -r . -f json -o bandit_report.json \%0A+             --exclude '**/tests/**,**/test_*.py,**/validate_*.py' \%0A+             --skip B101,B311,B105,B107,B108,B104,B110 || true%0A+           %0A+           # Generate clean SARIF output using heredoc to avoid shell quoting issues%0A+           python - <<'EOF'%0A+           import json%0A+           import sys%0A+           %0A+           def create_minimal_sarif():%0A+               """Create a minimal valid SARIF structure."""%0A+               return {%0A+                   "$schema": "https://raw.githubusercontent.com/oasis-tcs/sarif-spec/master/Schemata/sarif-schema-2.1.0.json",%0A+                   "version": "2.1.0",%0A+                   "runs": [{%0A+                       "tool": {%0A+                           "driver": {%0A+                               "name": "Bandit",%0A+                               "version": "1.7.0"%0A+                           }%0A+                       },%0A+                       "results": []%0A+                   }]%0A+               }%0A+           %0A+           try:%0A+               # Read Bandit JSON report%0A+               with open('bandit_report.json', 'r') as f:%0A+                   bandit_data = json.load(f)%0A+               %0A+               # Validate that we have the expected structure%0A+               if not isinstance(bandit_data, dict):%0A+                   print(f"âš ï¸  bandit_report.json is not a dict, creating minimal SARIF")%0A+                   sarif = create_minimal_sarif()%0A+               else:%0A+                   # Create valid SARIF 2.1.0 format - only standard properties%0A+                   sarif = create_minimal_sarif()%0A+                   %0A+                   # Process Bandit results - only HIGH and MEDIUM severity%0A+                   results = bandit_data.get('results', [])%0A+                   if not isinstance(results, list):%0A+                       print(f"âš ï¸  'results' is not a list in bandit_report.json")%0A+                       results = []%0A+                   %0A+                   for issue in results:%0A+                       if not isinstance(issue, dict):%0A+                           continue%0A+                       %0A+                       severity = issue.get('issue_severity', '')%0A+                       if severity in ['HIGH', 'MEDIUM']:%0A+                           sarif['runs'][0]['results'].append({%0A+                               'ruleId': issue.get('test_id', 'unknown'),%0A+                               'level': 'error' if severity == 'HIGH' else 'warning',%0A+                               'message': {%0A+                                   'text': issue.get('issue_text', 'No description provided')%0A+                               },%0A+                               'locations': [{%0A+                                   'physicalLocation': {%0A+                                       'artifactLocation': {%0A+                                           'uri': issue.get('filename', 'unknown').replace('./', '')%0A+                                       },%0A+                                       'region': {%0A+                                           'startLine': issue.get('line_number', 1),%0A+                                           'startColumn': issue.get('col_offset', 1)%0A+                                       }%0A+                                   }%0A+                               }]%0A+                           })%0A+                   %0A+                   print(f"ðŸ“Š Generated SARIF with {len(sarif['runs'][0]['results'])} high/medium severity issues")%0A+               %0A+               # Write clean SARIF - no 'errors' or 'generated_at' properties%0A+               with open('bandit_sarif.json', 'w') as f:%0A+                   json.dump(sarif, f, indent=2)%0A+               %0A+               print("âœ… SARIF file written successfully")%0A+               %0A+           except FileNotFoundError:%0A+               print("âš ï¸  bandit_report.json not found, creating minimal SARIF")%0A+               sarif = create_minimal_sarif()%0A+               with open('bandit_sarif.json', 'w') as f:%0A+                   json.dump(sarif, f, indent=2)%0A+           except json.JSONDecodeError as e:%0A+               print(f"âŒ Failed to parse bandit_report.json: {e}")%0A+               print("Creating minimal valid SARIF")%0A+               sarif = create_minimal_sarif()%0A+               with open('bandit_sarif.json', 'w') as f:%0A+                   json.dump(sarif, f, indent=2)%0A+           except Exception as e:%0A+               print(f"âŒ Unexpected error: {e}")%0A+               sarif = create_minimal_sarif()%0A+               with open('bandit_sarif.json', 'w') as f:%0A+                   json.dump(sarif, f, indent=2)%0A+           EOF%0A+           %0A+           # Validate generated SARIF%0A+           echo "ðŸ” Validating generated SARIF file:"%0A+           head -20 bandit_sarif.json%0A+           %0A+           # Verify required properties exist%0A+           python - <<'EOF'%0A+           import json%0A+           try:%0A+               with open('bandit_sarif.json', 'r') as f:%0A+                   sarif = json.load(f)%0A+               %0A+               # Check required SARIF properties%0A+               assert '$schema' in sarif, "Missing $schema property"%0A+               assert 'version' in sarif, "Missing version property"%0A+               assert 'runs' in sarif, "Missing runs property"%0A+               assert isinstance(sarif['runs'], list), "runs must be a list"%0A+               assert len(sarif['runs']) > 0, "runs must not be empty"%0A+               %0A+               # Check no extra top-level properties%0A+               allowed_keys = {'$schema', 'version', 'runs'}%0A+               extra_keys = set(sarif.keys()) - allowed_keys%0A+               if extra_keys:%0A+                   print(f"âš ï¸  Found unexpected top-level keys: {extra_keys}")%0A+                   sys.exit(1)%0A+               %0A+               print("âœ… SARIF validation passed")%0A+           except Exception as e:%0A+               print(f"âŒ SARIF validation failed: {e}")%0A+               import sys%0A+               sys.exit(1)%0A+           EOF%0A+         working-directory: backend%0A+%0A+       - name: Upload Security Scan Results%0A+         uses: github/codeql-action/upload-sarif@v3%0A+         if: always()%0A+         with:%0A+           sarif_file: backend/bandit_sarif.json%0A+%0A+       - name: Upload Bandit Report Artifact%0A+         uses: actions/upload-artifact@v4%0A+         if: always()%0A+         with:%0A+           name: bandit-security-report%0A+           path: backend/bandit_report.json%0A+%0A+   dependency-and-secret-scanning:%0A+     runs-on: ubuntu-latest%0A+     steps:%0A+       - name: Checkout code%0A+         uses: actions/checkout@v4%0A+%0A+       - name: Install and Run Gitleaks Properly%0A+         run: |%0A+           # Install gitleaks with proper configuration%0A+           curl -sSfL https://github.com/gitleaks/gitleaks/releases/download/v8.18.1/gitleaks_8.18.1_linux_x64.tar.gz | tar xz -C /tmp/%0A+           chmod +x /tmp/gitleaks%0A+           sudo mv /tmp/gitleaks /usr/local/bin/%0A+           %0A+           echo "ðŸ” Creating gitleaks configuration..."%0A+           # Create a proper config file that excludes test files and documentation%0A+           cat > .gitleaks.toml << 'EOF'%0A+           title = "ThermaCoreApp Gitleaks Config"%0A+           [allowlist]%0A+             description = "Allow test files and documentation"%0A+             files = [%0A+               '''.*\.md$''',%0A+               '''.*\.txt$''',%0A+               '''.*test.*\.py$''',%0A+               '''.*Test.*\.py$''',%0A+               '''.*spec.*\.py$''',%0A+               '''.*fixture.*\.py$''',%0A+               '''conftest\.py$''',%0A+               '''.*__init__\.py$''',%0A+               '''.*\.lock$''',%0A+               '''.*\.json$''',%0A+               '''.*\.yml$''',%0A+               '''.*\.yaml$''',%0A+               '''\.env\.example$''',%0A+               '''\.gitignore$''',%0A+               '''bandit_report\.json$''',%0A+               '''coverage\.xml$''',%0A+               '''.*\.html$''',%0A+               '''.*\.sql$''',%0A+               '''.*\.log$''',%0A+               '''\.github/workflows/.*''',%0A+               '''backend/app/tests/.*''',%0A+               '''backend/app/utils/validate_secure_logging\.py$''',%0A+               '''backend/SECURITY_.*''',%0A+               '''backend/SECRET_.*''',%0A+               '''backend/SECURE_.*''',%0A+               '''frontend/src/__tests__/.*''',%0A+             ]%0A+           EOF%0A+           %0A+           echo "ðŸ” Running gitleaks secret scan with proper config..."%0A+           gitleaks detect --source . --config .gitleaks.toml --no-git --verbose --redact%0A+           %0A+           echo "âœ… Gitleaks scan completed successfully"%0A+%0A+       - name: Dependency Review%0A+         if: github.event_name == 'pull_request'%0A+         uses: actions/dependency-review-action@v4%0A+%0A+       - name: Run OSV Scanner with Go Install (Most Reliable)%0A+         run: |%0A+           echo "ðŸ”§ Installing OSV Scanner via Go install..."%0A+           # Install Go if not present%0A+           if ! command -v go &> /dev/null; then%0A+             curl -L https://golang.org/dl/go1.21.0.linux-amd64.tar.gz | sudo tar -C /usr/local -xzf -%0A+             echo 'export PATH=$PATH:/usr/local/go/bin' >> ~/.bashrc%0A+             source ~/.bashrc%0A+           fi%0A+           %0A+           # Install OSV Scanner via Go%0A+           go install github.com/google/osv-scanner/cmd/osv-scanner@v1%0A+           %0A+           echo "ðŸ” Running OSV Scanner..."%0A+           ~/go/bin/osv-scanner -r . --skip-git || echo "OSV Scanner completed with findings"%0A+%0A+   dependabot-auto-merge:%0A+     runs-on: ubuntu-latest%0A+     if: ${{ github.actor == 'dependabot[bot]' }}%0A+     permissions:%0A+       contents: write%0A+       pull-requests: write%0A+     steps:%0A+       - name: Dependabot metadata%0A+         id: metadata%0A+         uses: dependabot/fetch-metadata@v2%0A+         with:%0A+           github-token: "${{ secrets.GITHUB_TOKEN }}"%0A+%0A+       - name: Enable auto-merge for Dependabot PRs%0A+         if: ${{ steps.metadata.outputs.update-type == 'version-update:semver-patch' }}%0A+         run: |%0A+           gh pr merge --auto --merge "${{ github.event.pull_request.html_url }}"%0A+         env:%0A+           GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}%0A+%0A+       - name: Approve Dependabot PRs%0A+         if: ${{ steps.metadata.outputs.update-type == 'version-update:semver-patch' }}%0A+         run: |%0A+           gh pr review --approve "${{ github.event.pull_request.html_url }}"%0A+         env:%0A+           GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}%0A+%0A%0A â¯ src/tests/workflow.test.js:27:29%0A%0A
â€‰ELIFECYCLEâ€‰ Test failed. See above for more details.

    â—‹
    â”‚â•²
    â”‚ â—‹
    â—‹ â–‘
    â–‘    gitleaks

[90m9:53AM[0m [32mINF[0m scan completed in 1.73s
[90m9:53AM[0m [32mINF[0m no leaks found
